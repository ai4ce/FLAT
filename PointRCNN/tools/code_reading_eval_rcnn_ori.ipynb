{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _init_path\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from lib.net.point_rcnn import PointRCNN\n",
    "from lib.datasets.kitti_rcnn_dataset import KittiRCNNDataset\n",
    "import tools.train_utils.train_utils as train_utils\n",
    "from lib.utils.bbox_transform import decode_bbox_target\n",
    "from tools.kitti_object_eval_python.evaluate import evaluate as kitti_evaluate\n",
    "\n",
    "from lib.config import cfg, cfg_from_file, save_config_to_file, cfg_from_list\n",
    "import argparse\n",
    "import lib.utils.kitti_utils as kitti_utils\n",
    "import lib.utils.iou3d.iou3d_utils as iou3d_utils\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import re\n",
    "import glob\n",
    "import time\n",
    "from tensorboardX import SummaryWriter\n",
    "import tqdm\n",
    "\n",
    "\n",
    "np.random.seed(1024)  # set the same seed\n",
    "\n",
    "# parser = argparse.ArgumentParser(description=\"arg parser\")\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--cfg_file', type=str, default='cfgs/default.yml', help='specify the config for evaluation')\n",
    "parser.add_argument(\"--eval_mode\", type=str, default='rpn', help=\"specify the evaluation mode\")\n",
    "\n",
    "parser.add_argument('--eval_all', action='store_true', default=False, help='whether to evaluate all checkpoints')\n",
    "parser.add_argument('--test', action='store_true', default=False, help='evaluate without ground truth')\n",
    "parser.add_argument(\"--ckpt\", type=str, default=None, help=\"specify a checkpoint to be evaluated\")\n",
    "parser.add_argument(\"--rpn_ckpt\", type=str, default=None, help=\"specify the checkpoint of rpn if trained separated\")\n",
    "parser.add_argument(\"--rcnn_ckpt\", type=str, default=None, help=\"specify the checkpoint of rcnn if trained separated\")\n",
    "\n",
    "parser.add_argument('--batch_size', type=int, default=1, help='batch size for evaluation')\n",
    "parser.add_argument('--workers', type=int, default=4, help='number of workers for dataloader')\n",
    "parser.add_argument(\"--extra_tag\", type=str, default='nuscenes', help=\"extra tag for multiple evaluation\")\n",
    "parser.add_argument('--output_dir', type=str, default=None, help='specify an output directory if needed')\n",
    "parser.add_argument(\"--ckpt_dir\", type=str, default=None, help=\"specify a ckpt directory to be evaluated if needed\")\n",
    "\n",
    "parser.add_argument('--save_result', action='store_true', default=False, help='save evaluation results to files')\n",
    "parser.add_argument('--save_rpn_feature', action='store_true', default=False,\n",
    "                    help='save features for separately rcnn training and evaluation')\n",
    "\n",
    "parser.add_argument('--random_select', action='store_true', default=True, help='sample to the same number of points')\n",
    "parser.add_argument('--start_epoch', default=0, type=int, help='ignore the checkpoint smaller than this epoch')\n",
    "parser.add_argument(\"--rcnn_eval_roi_dir\", type=str, default=None,\n",
    "                    help='specify the saved rois for rcnn evaluation when using rcnn_offline mode')\n",
    "parser.add_argument(\"--rcnn_eval_feature_dir\", type=str, default=None,\n",
    "                    help='specify the saved features for rcnn evaluation when using rcnn_offline mode')\n",
    "parser.add_argument('--set', dest='set_cfgs', default=None, nargs=argparse.REMAINDER,\n",
    "                    help='set extra config keys if needed')\n",
    "args = parser.parse_args(args=['--cfg_file', 'cfgs/default.yaml', '--ckpt', 'PointRCNN.pth', '--batch_size', '1', '--eval_mode', 'rcnn', '--set', 'RPN.LOC_XZ_FINE', 'False'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_logger(log_file):\n",
    "    log_format = '%(asctime)s  %(levelname)5s  %(message)s'\n",
    "    logging.basicConfig(level=logging.INFO, format=log_format, filename=log_file)\n",
    "    console = logging.StreamHandler()\n",
    "    console.setLevel(logging.INFO)\n",
    "    console.setFormatter(logging.Formatter(log_format))\n",
    "    logging.getLogger(__name__).addHandler(console)\n",
    "    return logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def save_kitti_format(sample_id, calib, bbox3d, kitti_output_dir, scores, img_shape):\n",
    "    corners3d = kitti_utils.boxes3d_to_corners3d(bbox3d)\n",
    "    img_boxes, _ = calib.corners3d_to_img_boxes(corners3d)\n",
    "\n",
    "    img_boxes[:, 0] = np.clip(img_boxes[:, 0], 0, img_shape[1] - 1)\n",
    "    img_boxes[:, 1] = np.clip(img_boxes[:, 1], 0, img_shape[0] - 1)\n",
    "    img_boxes[:, 2] = np.clip(img_boxes[:, 2], 0, img_shape[1] - 1)\n",
    "    img_boxes[:, 3] = np.clip(img_boxes[:, 3], 0, img_shape[0] - 1)\n",
    "\n",
    "    img_boxes_w = img_boxes[:, 2] - img_boxes[:, 0]\n",
    "    img_boxes_h = img_boxes[:, 3] - img_boxes[:, 1]\n",
    "    box_valid_mask = np.logical_and(img_boxes_w < img_shape[1] * 0.8, img_boxes_h < img_shape[0] * 0.8)\n",
    "\n",
    "    kitti_output_file = os.path.join(kitti_output_dir, '%06d.txt' % sample_id)\n",
    "    with open(kitti_output_file, 'w') as f:\n",
    "        for k in range(bbox3d.shape[0]):\n",
    "            if box_valid_mask[k] == 0:\n",
    "                continue\n",
    "            x, z, ry = bbox3d[k, 0], bbox3d[k, 2], bbox3d[k, 6]\n",
    "            beta = np.arctan2(z, x)\n",
    "            alpha = -np.sign(beta) * np.pi / 2 + beta + ry\n",
    "            print('%s -1 -1 %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f' %(cfg.CLASSES, alpha, img_boxes[k, 0], img_boxes[k, 1], img_boxes[k, 2], img_boxes[k, 3], bbox3d[k, 3], bbox3d[k, 4], bbox3d[k, 5], bbox3d[k, 0], bbox3d[k, 1], bbox3d[k, 2], bbox3d[k, 6], scores[k]), file=f)\n",
    "\n",
    "def save_rpn_features(seg_result, rpn_scores_raw, pts_features, backbone_xyz, backbone_features, kitti_features_dir,\n",
    "                      sample_id):\n",
    "    pts_intensity = pts_features[:, 0]\n",
    "\n",
    "    output_file = os.path.join(kitti_features_dir, '%06d.npy' % sample_id)\n",
    "    xyz_file = os.path.join(kitti_features_dir, '%06d_xyz.npy' % sample_id)\n",
    "    seg_file = os.path.join(kitti_features_dir, '%06d_seg.npy' % sample_id)\n",
    "    intensity_file = os.path.join(kitti_features_dir, '%06d_intensity.npy' % sample_id)\n",
    "    np.save(output_file, backbone_features)\n",
    "    np.save(xyz_file, backbone_xyz)\n",
    "    np.save(seg_file, seg_result)\n",
    "    np.save(intensity_file, pts_intensity)\n",
    "    rpn_scores_raw_file = os.path.join(kitti_features_dir, '%06d_rawscore.npy' % sample_id)\n",
    "    np.save(rpn_scores_raw_file, rpn_scores_raw)\n",
    "\n",
    "\n",
    "def eval_one_epoch_rpn(model, dataloader, epoch_id, result_dir, logger):\n",
    "    np.random.seed(1024)\n",
    "    mode = 'TEST' if args.test else 'EVAL'\n",
    "\n",
    "    if args.save_rpn_feature:\n",
    "        kitti_features_dir = os.path.join(result_dir, 'features')\n",
    "        os.makedirs(kitti_features_dir, exist_ok=True)\n",
    "\n",
    "    if args.save_result or args.save_rpn_feature:\n",
    "        kitti_output_dir = os.path.join(result_dir, 'detections', 'data')\n",
    "        seg_output_dir = os.path.join(result_dir, 'seg_result')\n",
    "        os.makedirs(kitti_output_dir, exist_ok=True)\n",
    "        os.makedirs(seg_output_dir, exist_ok=True)\n",
    "\n",
    "    logger.info('---- EPOCH %s RPN EVALUATION ----' % epoch_id)\n",
    "    model.eval()\n",
    "\n",
    "    thresh_list = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "    total_recalled_bbox_list, total_gt_bbox = [0] * 5, 0\n",
    "    dataset = dataloader.dataset\n",
    "    cnt = max_num = rpn_iou_avg = 0\n",
    "\n",
    "    progress_bar = tqdm.tqdm(total=len(dataloader), leave=True, desc='eval')\n",
    "\n",
    "    for data in dataloader:\n",
    "        sample_id_list, pts_rect, pts_features, pts_input = \\\n",
    "            data['sample_id'], data['pts_rect'], data['pts_features'], data['pts_input']\n",
    "        sample_id = sample_id_list[0]\n",
    "        cnt += len(sample_id_list)\n",
    "\n",
    "        if not args.test:\n",
    "            rpn_cls_label, rpn_reg_label = data['rpn_cls_label'], data['rpn_reg_label']\n",
    "            gt_boxes3d = data['gt_boxes3d']\n",
    "\n",
    "            rpn_cls_label = torch.from_numpy(rpn_cls_label).cuda(non_blocking=True).long()\n",
    "            if gt_boxes3d.shape[1] == 0:  # (B, M, 7)\n",
    "                pass\n",
    "                # logger.info('%06d: No gt box' % sample_id)\n",
    "            else:\n",
    "                gt_boxes3d = torch.from_numpy(gt_boxes3d).cuda(non_blocking=True).float()\n",
    "\n",
    "        inputs = torch.from_numpy(pts_input).cuda(non_blocking=True).float()\n",
    "        input_data = {'pts_input': inputs}\n",
    "\n",
    "        # model inference\n",
    "        ret_dict = model(input_data)\n",
    "        rpn_cls, rpn_reg = ret_dict['rpn_cls'], ret_dict['rpn_reg']\n",
    "        backbone_xyz, backbone_features = ret_dict['backbone_xyz'], ret_dict['backbone_features']\n",
    "\n",
    "        rpn_scores_raw = rpn_cls[:, :, 0]\n",
    "        rpn_scores = torch.sigmoid(rpn_scores_raw)\n",
    "        seg_result = (rpn_scores > cfg.RPN.SCORE_THRESH).long()\n",
    "\n",
    "        # proposal layer\n",
    "        rois, roi_scores_raw = model.rpn.proposal_layer(rpn_scores_raw, rpn_reg, backbone_xyz)  # (B, M, 7)\n",
    "        batch_size = rois.shape[0]\n",
    "\n",
    "        # calculate recall and save results to file\n",
    "        for bs_idx in range(batch_size):\n",
    "            cur_sample_id = sample_id_list[bs_idx]\n",
    "            cur_scores_raw = roi_scores_raw[bs_idx]  # (N)\n",
    "            cur_boxes3d = rois[bs_idx]  # (N, 7)\n",
    "            cur_seg_result = seg_result[bs_idx]\n",
    "            cur_pts_rect = pts_rect[bs_idx]\n",
    "\n",
    "            # calculate recall\n",
    "            if not args.test:\n",
    "                cur_rpn_cls_label = rpn_cls_label[bs_idx]\n",
    "                cur_gt_boxes3d = gt_boxes3d[bs_idx]\n",
    "\n",
    "                k = cur_gt_boxes3d.__len__() - 1\n",
    "                while k > 0 and cur_gt_boxes3d[k].sum() == 0:\n",
    "                    k -= 1\n",
    "                cur_gt_boxes3d = cur_gt_boxes3d[:k + 1]\n",
    "\n",
    "                recalled_num = 0\n",
    "                if cur_gt_boxes3d.shape[0] > 0:\n",
    "                    iou3d = iou3d_utils.boxes_iou3d_gpu(cur_boxes3d, cur_gt_boxes3d[:, 0:7])\n",
    "                    gt_max_iou, _ = iou3d.max(dim=0)\n",
    "\n",
    "                    for idx, thresh in enumerate(thresh_list):\n",
    "                        total_recalled_bbox_list[idx] += (gt_max_iou > thresh).sum().item()\n",
    "                    recalled_num = (gt_max_iou > 0.7).sum().item()\n",
    "                    total_gt_bbox += cur_gt_boxes3d.__len__()\n",
    "\n",
    "                fg_mask = cur_rpn_cls_label > 0\n",
    "                correct = ((cur_seg_result == cur_rpn_cls_label) & fg_mask).sum().float()\n",
    "                union = fg_mask.sum().float() + (cur_seg_result > 0).sum().float() - correct\n",
    "                rpn_iou = correct / torch.clamp(union, min=1.0)\n",
    "                rpn_iou_avg += rpn_iou.item()\n",
    "\n",
    "            # save result\n",
    "            if args.save_rpn_feature:\n",
    "                # save features to file\n",
    "                save_rpn_features(seg_result[bs_idx].float().cpu().numpy(),\n",
    "                                  rpn_scores_raw[bs_idx].float().cpu().numpy(),\n",
    "                                  pts_features[bs_idx],\n",
    "                                  backbone_xyz[bs_idx].cpu().numpy(),\n",
    "                                  backbone_features[bs_idx].cpu().numpy().transpose(1, 0),\n",
    "                                  kitti_features_dir, cur_sample_id)\n",
    "\n",
    "            if args.save_result or args.save_rpn_feature:\n",
    "                cur_pred_cls = cur_seg_result.cpu().numpy()\n",
    "                output_file = os.path.join(seg_output_dir, '%06d.npy' % cur_sample_id)\n",
    "                if not args.test:\n",
    "                    cur_gt_cls = cur_rpn_cls_label.cpu().numpy()\n",
    "                    output_data = np.concatenate(\n",
    "                        (cur_pts_rect.reshape(-1, 3), cur_gt_cls.reshape(-1, 1), cur_pred_cls.reshape(-1, 1)), axis=1)\n",
    "                else:\n",
    "                    output_data = np.concatenate((cur_pts_rect.reshape(-1, 3), cur_pred_cls.reshape(-1, 1)), axis=1)\n",
    "\n",
    "                np.save(output_file, output_data.astype(np.float16))\n",
    "\n",
    "                # save as kitti format\n",
    "                calib = dataset.get_calib(cur_sample_id)\n",
    "                cur_boxes3d = cur_boxes3d.cpu().numpy()\n",
    "                image_shape = dataset.get_image_shape(cur_sample_id)\n",
    "                save_kitti_format(cur_sample_id, calib, cur_boxes3d, kitti_output_dir, cur_scores_raw, image_shape)\n",
    "\n",
    "        disp_dict = {'mode': mode, 'recall': '%d/%d' % (total_recalled_bbox_list[3], total_gt_bbox),\n",
    "                     'rpn_iou': rpn_iou_avg / max(cnt, 1.0)}\n",
    "        progress_bar.set_postfix(disp_dict)\n",
    "        progress_bar.update()\n",
    "\n",
    "    progress_bar.close()\n",
    "\n",
    "    logger.info(str(datetime.now()))\n",
    "    logger.info('-------------------performance of epoch %s---------------------' % epoch_id)\n",
    "    logger.info('max number of objects: %d' % max_num)\n",
    "    logger.info('rpn iou avg: %f' % (rpn_iou_avg / max(cnt, 1.0)))\n",
    "\n",
    "    ret_dict = {'max_obj_num': max_num, 'rpn_iou': rpn_iou_avg / cnt}\n",
    "\n",
    "    for idx, thresh in enumerate(thresh_list):\n",
    "        cur_recall = total_recalled_bbox_list[idx] / max(total_gt_bbox, 1.0)\n",
    "        logger.info('total bbox recall(thresh=%.3f): %d / %d = %f' % (thresh, total_recalled_bbox_list[idx],\n",
    "                    total_gt_bbox, cur_recall))\n",
    "        ret_dict['rpn_recall(thresh=%.2f)' % thresh] = cur_recall\n",
    "    logger.info('result is saved to: %s' % result_dir)\n",
    "\n",
    "    return ret_dict\n",
    "\n",
    "\n",
    "def eval_one_epoch_rcnn(model, dataloader, epoch_id, result_dir, logger):\n",
    "    np.random.seed(1024)\n",
    "    MEAN_SIZE = torch.from_numpy(cfg.CLS_MEAN_SIZE[0]).cuda()\n",
    "    mode = 'TEST' if args.test else 'EVAL'\n",
    "\n",
    "    final_output_dir = os.path.join(result_dir, 'final_result', 'data')\n",
    "    os.makedirs(final_output_dir, exist_ok=True)\n",
    "\n",
    "    if args.save_result:\n",
    "        roi_output_dir = os.path.join(result_dir, 'roi_result', 'data')\n",
    "        refine_output_dir = os.path.join(result_dir, 'refine_result', 'data')\n",
    "        os.makedirs(roi_output_dir, exist_ok=True)\n",
    "        os.makedirs(refine_output_dir, exist_ok=True)\n",
    "\n",
    "    logger.info('---- EPOCH %s RCNN EVALUATION ----' % epoch_id)\n",
    "    model.eval()\n",
    "\n",
    "    thresh_list = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "    total_recalled_bbox_list, total_gt_bbox = [0] * 5, 0\n",
    "    total_roi_recalled_bbox_list = [0] * 5\n",
    "    dataset = dataloader.dataset\n",
    "    cnt = final_total = total_cls_acc = total_cls_acc_refined = 0\n",
    "\n",
    "    progress_bar = tqdm.tqdm(total=len(dataloader), leave=True, desc='eval')\n",
    "    for data in dataloader:\n",
    "        sample_id = data['sample_id']\n",
    "        cnt += 1\n",
    "        assert args.batch_size == 1, 'Only support bs=1 here'\n",
    "        input_data = {}\n",
    "        for key, val in data.items():\n",
    "            if key != 'sample_id':\n",
    "                input_data[key] = torch.from_numpy(val).contiguous().cuda(non_blocking=True).float()\n",
    "\n",
    "        roi_boxes3d = input_data['roi_boxes3d']\n",
    "        roi_scores = input_data['roi_scores']\n",
    "        if cfg.RCNN.ROI_SAMPLE_JIT:\n",
    "            for key, val in input_data.items():\n",
    "                if key in ['gt_iou', 'gt_boxes3d']:\n",
    "                    continue\n",
    "                input_data[key] = input_data[key].unsqueeze(dim=0)\n",
    "        else:\n",
    "            pts_input = torch.cat((input_data['pts_input'], input_data['pts_features']), dim=-1)\n",
    "            input_data['pts_input'] = pts_input\n",
    "\n",
    "        ret_dict = model(input_data)\n",
    "        rcnn_cls = ret_dict['rcnn_cls']\n",
    "        rcnn_reg = ret_dict['rcnn_reg']\n",
    "\n",
    "        # bounding box regression\n",
    "        anchor_size = MEAN_SIZE\n",
    "        if cfg.RCNN.SIZE_RES_ON_ROI:\n",
    "            roi_size = input_data['roi_size']\n",
    "            anchor_size = roi_size\n",
    "\n",
    "        pred_boxes3d = decode_bbox_target(roi_boxes3d, rcnn_reg,\n",
    "                                          anchor_size=anchor_size,\n",
    "                                          loc_scope=cfg.RCNN.LOC_SCOPE,\n",
    "                                          loc_bin_size=cfg.RCNN.LOC_BIN_SIZE,\n",
    "                                          num_head_bin=cfg.RCNN.NUM_HEAD_BIN,\n",
    "                                          get_xz_fine=True, get_y_by_bin=cfg.RCNN.LOC_Y_BY_BIN,\n",
    "                                          loc_y_scope=cfg.RCNN.LOC_Y_SCOPE, loc_y_bin_size=cfg.RCNN.LOC_Y_BIN_SIZE,\n",
    "                                          get_ry_fine=True)\n",
    "\n",
    "        # scoring\n",
    "        if rcnn_cls.shape[1] == 1:\n",
    "            raw_scores = rcnn_cls.view(-1)\n",
    "            norm_scores = torch.sigmoid(raw_scores)\n",
    "            pred_classes = (norm_scores > cfg.RCNN.SCORE_THRESH).long()\n",
    "        else:\n",
    "            pred_classes = torch.argmax(rcnn_cls, dim=1).view(-1)\n",
    "            cls_norm_scores = F.softmax(rcnn_cls, dim=1)\n",
    "            raw_scores = rcnn_cls[:, pred_classes]\n",
    "            norm_scores = cls_norm_scores[:, pred_classes]\n",
    "\n",
    "        # evaluation\n",
    "        disp_dict = {'mode': mode}\n",
    "        if not args.test:\n",
    "            gt_boxes3d = input_data['gt_boxes3d']\n",
    "            gt_iou = input_data['gt_iou']\n",
    "\n",
    "            # calculate recall\n",
    "            gt_num = gt_boxes3d.shape[0]\n",
    "            if gt_num > 0:\n",
    "                iou3d = iou3d_utils.boxes_iou3d_gpu(pred_boxes3d, gt_boxes3d)\n",
    "                gt_max_iou, _ = iou3d.max(dim=0)\n",
    "                refined_iou, _ = iou3d.max(dim=1)\n",
    "\n",
    "                for idx, thresh in enumerate(thresh_list):\n",
    "                    total_recalled_bbox_list[idx] += (gt_max_iou > thresh).sum().item()\n",
    "                recalled_num = (gt_max_iou > 0.7).sum().item()\n",
    "                total_gt_bbox += gt_num\n",
    "\n",
    "                iou3d_in = iou3d_utils.boxes_iou3d_gpu(roi_boxes3d, gt_boxes3d)\n",
    "                gt_max_iou_in, _ = iou3d_in.max(dim=0)\n",
    "\n",
    "                for idx, thresh in enumerate(thresh_list):\n",
    "                    total_roi_recalled_bbox_list[idx] += (gt_max_iou_in > thresh).sum().item()\n",
    "\n",
    "            # classification accuracy\n",
    "            cls_label = (gt_iou > cfg.RCNN.CLS_FG_THRESH).float()\n",
    "            cls_valid_mask = ((gt_iou >= cfg.RCNN.CLS_FG_THRESH) | (gt_iou <= cfg.RCNN.CLS_BG_THRESH)).float()\n",
    "            cls_acc = ((pred_classes == cls_label.long()).float() * cls_valid_mask).sum() / max(cls_valid_mask.sum(), 1.0)\n",
    "\n",
    "            iou_thresh = 0.7 if cfg.CLASSES == 'Car' else 0.5\n",
    "            cls_label_refined = (gt_iou >= iou_thresh).float()\n",
    "            cls_acc_refined = (pred_classes == cls_label_refined.long()).float().sum() / max(cls_label_refined.shape[0], 1.0)\n",
    "\n",
    "            total_cls_acc += cls_acc.item()\n",
    "            total_cls_acc_refined += cls_acc_refined.item()\n",
    "\n",
    "            disp_dict['recall'] = '%d/%d' % (total_recalled_bbox_list[3], total_gt_bbox)\n",
    "            disp_dict['cls_acc_refined'] = '%.2f' % cls_acc_refined.item()\n",
    "\n",
    "        progress_bar.set_postfix(disp_dict)\n",
    "        progress_bar.update()\n",
    "\n",
    "        image_shape = dataset.get_image_shape(sample_id)\n",
    "        if args.save_result:\n",
    "            # save roi and refine results\n",
    "            roi_boxes3d_np = roi_boxes3d.cpu().numpy()\n",
    "            pred_boxes3d_np = pred_boxes3d.cpu().numpy()\n",
    "            calib = dataset.get_calib(sample_id)\n",
    "\n",
    "            save_kitti_format(sample_id, calib, roi_boxes3d_np, roi_output_dir, roi_scores, image_shape)\n",
    "            save_kitti_format(sample_id, calib, pred_boxes3d_np, refine_output_dir, raw_scores.cpu().numpy(),\n",
    "                              image_shape)\n",
    "\n",
    "        # NMS and scoring\n",
    "        # scores thresh\n",
    "        inds = norm_scores > cfg.RCNN.SCORE_THRESH\n",
    "        if inds.sum() == 0:\n",
    "            continue\n",
    "\n",
    "        pred_boxes3d_selected = pred_boxes3d[inds]\n",
    "        raw_scores_selected = raw_scores[inds]\n",
    "\n",
    "        # NMS thresh\n",
    "        boxes_bev_selected = kitti_utils.boxes3d_to_bev_torch(pred_boxes3d_selected)\n",
    "        keep_idx = iou3d_utils.nms_gpu(boxes_bev_selected, raw_scores_selected, cfg.RCNN.NMS_THRESH)\n",
    "        pred_boxes3d_selected = pred_boxes3d_selected[keep_idx]\n",
    "\n",
    "        scores_selected = raw_scores_selected[keep_idx]\n",
    "        pred_boxes3d_selected, scores_selected = pred_boxes3d_selected.cpu().numpy(), scores_selected.cpu().numpy()\n",
    "\n",
    "        calib = dataset.get_calib(sample_id)\n",
    "        final_total += pred_boxes3d_selected.shape[0]\n",
    "        save_kitti_format(sample_id, calib, pred_boxes3d_selected, final_output_dir, scores_selected, image_shape)\n",
    "\n",
    "    progress_bar.close()\n",
    "\n",
    "    # dump empty files\n",
    "    split_file = os.path.join(dataset.imageset_dir, '..', '..', 'ImageSets', dataset.split + '.txt')\n",
    "    split_file = os.path.abspath(split_file)\n",
    "    image_idx_list = [x.strip() for x in open(split_file).readlines()]\n",
    "    empty_cnt = 0\n",
    "    for k in range(image_idx_list.__len__()):\n",
    "        cur_file = os.path.join(final_output_dir, '%s.txt' % image_idx_list[k])\n",
    "        if not os.path.exists(cur_file):\n",
    "            with open(cur_file, 'w') as temp_f:\n",
    "                pass\n",
    "            empty_cnt += 1\n",
    "            logger.info('empty_cnt=%d: dump empty file %s' % (empty_cnt, cur_file))\n",
    "\n",
    "    ret_dict = {'empty_cnt': empty_cnt}\n",
    "\n",
    "    logger.info('-------------------performance of epoch %s---------------------' % epoch_id)\n",
    "    logger.info(str(datetime.now()))\n",
    "\n",
    "    avg_cls_acc = (total_cls_acc / max(cnt, 1.0))\n",
    "    avg_cls_acc_refined = (total_cls_acc_refined / max(cnt, 1.0))\n",
    "    avg_det_num = (final_total / max(cnt, 1.0))\n",
    "    logger.info('final average detections: %.3f' % avg_det_num)\n",
    "    logger.info('final average cls acc: %.3f' % avg_cls_acc)\n",
    "    logger.info('final average cls acc refined: %.3f' % avg_cls_acc_refined)\n",
    "    ret_dict['rcnn_cls_acc'] = avg_cls_acc\n",
    "    ret_dict['rcnn_cls_acc_refined'] = avg_cls_acc_refined\n",
    "    ret_dict['rcnn_avg_num'] = avg_det_num\n",
    "\n",
    "    for idx, thresh in enumerate(thresh_list):\n",
    "        cur_roi_recall = total_roi_recalled_bbox_list[idx] / max(total_gt_bbox, 1.0)\n",
    "        logger.info('total roi bbox recall(thresh=%.3f): %d / %d = %f' % (thresh, total_roi_recalled_bbox_list[idx],\n",
    "                                                                          total_gt_bbox, cur_roi_recall))\n",
    "        ret_dict['rpn_recall(thresh=%.2f)' % thresh] = cur_roi_recall\n",
    "\n",
    "    for idx, thresh in enumerate(thresh_list):\n",
    "        cur_recall = total_recalled_bbox_list[idx] / max(total_gt_bbox, 1.0)\n",
    "        logger.info('total bbox recall(thresh=%.3f): %d / %d = %f' % (thresh, total_recalled_bbox_list[idx],\n",
    "                                                                      total_gt_bbox, cur_recall))\n",
    "        ret_dict['rcnn_recall(thresh=%.2f)' % thresh] = cur_recall\n",
    "\n",
    "    if cfg.TEST.SPLIT != 'test':\n",
    "        logger.info('Averate Precision:')\n",
    "        name_to_class = {'Car': 0, 'Pedestrian': 1, 'Cyclist': 2}\n",
    "        ap_result_str, ap_dict = kitti_evaluate(dataset.label_dir, final_output_dir, label_split_file=split_file,\n",
    "                                                current_class=name_to_class[cfg.CLASSES])\n",
    "        logger.info(ap_result_str)\n",
    "        ret_dict.update(ap_dict)\n",
    "\n",
    "    logger.info('result is saved to: %s' % result_dir)\n",
    "\n",
    "    return ret_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_part_ckpt(model, filename, logger, total_keys=-1):\n",
    "    if os.path.isfile(filename):\n",
    "        logger.info(\"==> Loading part model from checkpoint '{}'\".format(filename))\n",
    "        checkpoint = torch.load(filename)\n",
    "        model_state = checkpoint['model_state']\n",
    "\n",
    "        update_model_state = {key: val for key, val in model_state.items() if key in model.state_dict()}\n",
    "        state_dict = model.state_dict()\n",
    "        state_dict.update(update_model_state)\n",
    "        model.load_state_dict(state_dict)\n",
    "\n",
    "        update_keys = update_model_state.keys().__len__()\n",
    "        if update_keys == 0:\n",
    "            raise RuntimeError\n",
    "        logger.info(\"==> Done (loaded %d/%d)\" % (update_keys, total_keys))\n",
    "    else:\n",
    "        raise FileNotFoundError\n",
    "\n",
    "\n",
    "def load_ckpt_based_on_args(model, logger):\n",
    "    if args.ckpt is not None:\n",
    "        train_utils.load_checkpoint(model, filename=args.ckpt, logger=logger)\n",
    "\n",
    "    total_keys = model.state_dict().keys().__len__()\n",
    "    if cfg.RPN.ENABLED and args.rpn_ckpt is not None:\n",
    "        load_part_ckpt(model, filename=args.rpn_ckpt, logger=logger, total_keys=total_keys)\n",
    "\n",
    "    if cfg.RCNN.ENABLED and args.rcnn_ckpt is not None:\n",
    "        load_part_ckpt(model, filename=args.rcnn_ckpt, logger=logger, total_keys=total_keys)\n",
    "\n",
    "\n",
    "# def eval_single_ckpt(root_result_dir):\n",
    "#     root_result_dir = os.path.join(root_result_dir, 'eval')\n",
    "#     # set epoch_id and output dir\n",
    "#     num_list = re.findall(r'\\d+', args.ckpt) if args.ckpt is not None else []\n",
    "#     epoch_id = num_list[-1] if num_list.__len__() > 0 else 'no_number'\n",
    "#     root_result_dir = os.path.join(root_result_dir, 'epoch_%s' % epoch_id, cfg.TEST.SPLIT)\n",
    "#     if args.test:\n",
    "#         root_result_dir = os.path.join(root_result_dir, 'test_mode')\n",
    "\n",
    "#     if args.extra_tag != 'default':\n",
    "#         root_result_dir = os.path.join(root_result_dir, args.extra_tag)\n",
    "#     os.makedirs(root_result_dir, exist_ok=True)\n",
    "\n",
    "#     log_file = os.path.join(root_result_dir, 'log_eval_one.txt')\n",
    "#     logger = create_logger(log_file)\n",
    "#     logger.info('**********************Start logging**********************')\n",
    "#     for key, val in vars(args).items():\n",
    "#         logger.info(\"{:16} {}\".format(key, val))\n",
    "#     save_config_to_file(cfg, logger=logger)\n",
    "\n",
    "#     # create dataloader & network\n",
    "#     test_loader = create_dataloader(logger)\n",
    "#     model = PointRCNN(num_classes=test_loader.dataset.num_class, use_xyz=True, mode='TEST')\n",
    "#     model.cuda()\n",
    "\n",
    "#     # copy important files to backup\n",
    "#     backup_dir = os.path.join(root_result_dir, 'backup_files')\n",
    "#     os.makedirs(backup_dir, exist_ok=True)\n",
    "#     os.system('cp *.py %s/' % backup_dir)\n",
    "#     os.system('cp ../lib/net/*.py %s/' % backup_dir)\n",
    "#     os.system('cp ../lib/datasets/kitti_rcnn_dataset.py %s/' % backup_dir)\n",
    "\n",
    "#     # load checkpoint\n",
    "#     load_ckpt_based_on_args(model, logger)\n",
    "\n",
    "#     # start evaluation\n",
    "#     eval_one_epoch(model, test_loader, epoch_id, root_result_dir, logger)\n",
    "\n",
    "\n",
    "def get_no_evaluated_ckpt(ckpt_dir, ckpt_record_file):\n",
    "    ckpt_list = glob.glob(os.path.join(ckpt_dir, '*checkpoint_epoch_*.pth'))\n",
    "    ckpt_list.sort(key=os.path.getmtime)\n",
    "    evaluated_ckpt_list = [float(x.strip()) for x in open(ckpt_record_file, 'r').readlines()]\n",
    "\n",
    "    for cur_ckpt in ckpt_list:\n",
    "        num_list = re.findall('checkpoint_epoch_(.*).pth', cur_ckpt)\n",
    "        if num_list.__len__() == 0:\n",
    "            continue\n",
    "\n",
    "        epoch_id = num_list[-1]\n",
    "        if float(epoch_id) not in evaluated_ckpt_list and int(float(epoch_id)) >= args.start_epoch:\n",
    "            return epoch_id, cur_ckpt\n",
    "    return -1, None\n",
    "\n",
    "\n",
    "def repeat_eval_ckpt(root_result_dir, ckpt_dir):\n",
    "    root_result_dir = os.path.join(root_result_dir, 'eval', 'eval_all_' + args.extra_tag)\n",
    "    os.makedirs(root_result_dir, exist_ok=True)\n",
    "\n",
    "    log_file = os.path.join(root_result_dir, 'log_eval_all_%s.txt' % cfg.TEST.SPLIT)\n",
    "    logger = create_logger(log_file)\n",
    "    logger.info('**********************Start logging**********************')\n",
    "\n",
    "    # save config\n",
    "    for key, val in vars(args).items():\n",
    "        logger.info(\"{:16} {}\".format(key, val))\n",
    "    save_config_to_file(cfg, logger=logger)\n",
    "\n",
    "    # create dataloader & network\n",
    "    test_loader = create_dataloader(logger)\n",
    "    model = PointRCNN(num_classes=test_loader.dataset.num_class, use_xyz=True, mode='TEST')\n",
    "    model.cuda()\n",
    "\n",
    "    # copy important files to backup\n",
    "    backup_dir = os.path.join(root_result_dir, 'backup_files')\n",
    "    os.makedirs(backup_dir, exist_ok=True)\n",
    "    os.system('cp *.py %s/' % backup_dir)\n",
    "    os.system('cp ../lib/net/*.py %s/' % backup_dir)\n",
    "    os.system('cp ../lib/datasets/kitti_rcnn_dataset.py %s/' % backup_dir)\n",
    "\n",
    "    # evaluated ckpt record\n",
    "    ckpt_record_file = os.path.join(root_result_dir, 'eval_list_%s.txt' % cfg.TEST.SPLIT)\n",
    "    with open(ckpt_record_file, 'a'):\n",
    "        pass\n",
    "\n",
    "    # tensorboard log\n",
    "    tb_log = SummaryWriter(log_dir=os.path.join(root_result_dir, 'tensorboard_%s' % cfg.TEST.SPLIT))\n",
    "\n",
    "    while True:\n",
    "        # check whether there is checkpoint which is not evaluated\n",
    "        cur_epoch_id, cur_ckpt = get_no_evaluated_ckpt(ckpt_dir, ckpt_record_file)\n",
    "        if cur_epoch_id == -1 or int(float(cur_epoch_id)) < args.start_epoch:\n",
    "            wait_second = 30\n",
    "            print('Wait %s second for next check: %s' % (wait_second, ckpt_dir))\n",
    "            time.sleep(wait_second)\n",
    "            continue\n",
    "\n",
    "        # load checkpoint\n",
    "        train_utils.load_checkpoint(model, filename=cur_ckpt)\n",
    "\n",
    "        # start evaluation\n",
    "        cur_result_dir = os.path.join(root_result_dir, 'epoch_%s' % cur_epoch_id, cfg.TEST.SPLIT)\n",
    "        tb_dict = eval_one_epoch(model, test_loader, cur_epoch_id, cur_result_dir, logger)\n",
    "\n",
    "        step = int(float(cur_epoch_id))\n",
    "        if step == float(cur_epoch_id):\n",
    "            for key, val in tb_dict.items():\n",
    "                tb_log.add_scalar(key, val, step)\n",
    "\n",
    "        # record this epoch which has been evaluated\n",
    "        with open(ckpt_record_file, 'a') as f:\n",
    "            print('%s' % cur_epoch_id, file=f)\n",
    "        logger.info('Epoch %s has been evaluated' % cur_epoch_id)\n",
    "\n",
    "\n",
    "def create_dataloader(logger):\n",
    "    mode = 'TEST' if args.test else 'EVAL'\n",
    "    DATA_PATH = os.path.join('..', 'data')\n",
    "    print(DATA_PATH)\n",
    "    # create dataloader\n",
    "    test_set = KittiRCNNDataset(root_dir=DATA_PATH, npoints=cfg.RPN.NUM_POINTS, split=cfg.TEST.SPLIT, mode=mode,\n",
    "                                random_select=args.random_select,\n",
    "                                rcnn_eval_roi_dir=args.rcnn_eval_roi_dir,\n",
    "                                rcnn_eval_feature_dir=args.rcnn_eval_feature_dir,\n",
    "                                classes=cfg.CLASSES,\n",
    "                                logger=logger)\n",
    "\n",
    "    test_loader = DataLoader(test_set, batch_size=args.batch_size, shuffle=False, pin_memory=True,\n",
    "                             num_workers=args.workers, collate_fn=test_set.collate_batch)\n",
    "\n",
    "    return test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../output/rcnn/default/ckpt'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge config and log to file\n",
    "if args.cfg_file is not None:\n",
    "    cfg_from_file(args.cfg_file)\n",
    "if args.set_cfgs is not None:\n",
    "    cfg_from_list(args.set_cfgs)\n",
    "cfg.TAG = os.path.splitext(os.path.basename(args.cfg_file))[0]\n",
    "\n",
    "if args.eval_mode == 'rpn':\n",
    "    cfg.RPN.ENABLED = True\n",
    "    cfg.RCNN.ENABLED = False\n",
    "    root_result_dir = os.path.join('../', 'output', 'rpn', cfg.TAG)\n",
    "    ckpt_dir = os.path.join('../', 'output', 'rpn', cfg.TAG, 'ckpt')\n",
    "elif args.eval_mode == 'rcnn':\n",
    "    cfg.RCNN.ENABLED = True\n",
    "    cfg.RPN.ENABLED = cfg.RPN.FIXED = True\n",
    "    root_result_dir = os.path.join('../', 'output', 'rcnn', cfg.TAG)\n",
    "    ckpt_dir = os.path.join('../', 'output', 'rcnn', cfg.TAG, 'ckpt')\n",
    "elif args.eval_mode == 'rcnn_offline':\n",
    "    cfg.RCNN.ENABLED = True\n",
    "    cfg.RPN.ENABLED = False\n",
    "    root_result_dir = os.path.join('../', 'output', 'rcnn', cfg.TAG)\n",
    "    ckpt_dir = os.path.join('../', 'output', 'rcnn', cfg.TAG, 'ckpt')\n",
    "    assert args.rcnn_eval_roi_dir is not None and args.rcnn_eval_feature_dir is not None\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "if args.ckpt_dir is not None:\n",
    "    ckpt_dir = args.ckpt_dir\n",
    "\n",
    "if args.output_dir is not None:\n",
    "    root_result_dir = args.output_dir\n",
    "\n",
    "os.makedirs(root_result_dir, exist_ok=True)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     if args.eval_all:\n",
    "#         assert os.path.exists(ckpt_dir), '%s' % ckpt_dir\n",
    "#         repeat_eval_ckpt(root_result_dir, ckpt_dir)\n",
    "#     else:\n",
    "#         eval_single_ckpt(root_result_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TAG': 'default',\n",
       " 'CLASSES': 'Car',\n",
       " 'INCLUDE_SIMILAR_TYPE': True,\n",
       " 'AUG_DATA': True,\n",
       " 'AUG_METHOD_LIST': ['rotation', 'scaling', 'flip'],\n",
       " 'AUG_METHOD_PROB': [1.0, 1.0, 0.5],\n",
       " 'AUG_ROT_RANGE': 18,\n",
       " 'GT_AUG_ENABLED': True,\n",
       " 'GT_EXTRA_NUM': 15,\n",
       " 'GT_AUG_RAND_NUM': True,\n",
       " 'GT_AUG_APPLY_PROB': 1.0,\n",
       " 'GT_AUG_HARD_RATIO': 0.6,\n",
       " 'PC_REDUCE_BY_RANGE': True,\n",
       " 'PC_AREA_SCOPE': array([[-40. ,  40. ],\n",
       "        [ -1. ,   3. ],\n",
       "        [  0. ,  70.4]]),\n",
       " 'CLS_MEAN_SIZE': array([[1.5256319, 1.6285675, 3.8831165]], dtype=float32),\n",
       " 'RPN': {'ENABLED': True,\n",
       "  'FIXED': True,\n",
       "  'USE_INTENSITY': False,\n",
       "  'LOC_XZ_FINE': False,\n",
       "  'LOC_SCOPE': 3.0,\n",
       "  'LOC_BIN_SIZE': 0.5,\n",
       "  'NUM_HEAD_BIN': 12,\n",
       "  'BACKBONE': 'pointnet2_msg',\n",
       "  'USE_BN': True,\n",
       "  'NUM_POINTS': 16384,\n",
       "  'SA_CONFIG': {'NPOINTS': [4096, 1024, 256, 64],\n",
       "   'RADIUS': [[0.1, 0.5], [0.5, 1.0], [1.0, 2.0], [2.0, 4.0]],\n",
       "   'NSAMPLE': [[16, 32], [16, 32], [16, 32], [16, 32]],\n",
       "   'MLPS': [[[16, 16, 32], [32, 32, 64]],\n",
       "    [[64, 64, 128], [64, 96, 128]],\n",
       "    [[128, 196, 256], [128, 196, 256]],\n",
       "    [[256, 256, 512], [256, 384, 512]]]},\n",
       "  'FP_MLPS': [[128, 128], [256, 256], [512, 512], [512, 512]],\n",
       "  'CLS_FC': [128],\n",
       "  'REG_FC': [128],\n",
       "  'DP_RATIO': 0.5,\n",
       "  'LOSS_CLS': 'SigmoidFocalLoss',\n",
       "  'FG_WEIGHT': 15,\n",
       "  'FOCAL_ALPHA': [0.25, 0.75],\n",
       "  'FOCAL_GAMMA': 2.0,\n",
       "  'REG_LOSS_WEIGHT': [1.0, 1.0, 1.0, 1.0],\n",
       "  'LOSS_WEIGHT': [1.0, 1.0],\n",
       "  'NMS_TYPE': 'normal',\n",
       "  'SCORE_THRESH': 0.3},\n",
       " 'RCNN': {'ENABLED': True,\n",
       "  'USE_RPN_FEATURES': True,\n",
       "  'USE_MASK': True,\n",
       "  'MASK_TYPE': 'seg',\n",
       "  'USE_INTENSITY': False,\n",
       "  'USE_DEPTH': True,\n",
       "  'USE_SEG_SCORE': False,\n",
       "  'ROI_SAMPLE_JIT': True,\n",
       "  'ROI_FG_AUG_TIMES': 10,\n",
       "  'REG_AUG_METHOD': 'multiple',\n",
       "  'POOL_EXTRA_WIDTH': 1.0,\n",
       "  'LOC_SCOPE': 1.5,\n",
       "  'LOC_BIN_SIZE': 0.5,\n",
       "  'NUM_HEAD_BIN': 9,\n",
       "  'LOC_Y_BY_BIN': False,\n",
       "  'LOC_Y_SCOPE': 0.5,\n",
       "  'LOC_Y_BIN_SIZE': 0.25,\n",
       "  'SIZE_RES_ON_ROI': False,\n",
       "  'USE_BN': False,\n",
       "  'DP_RATIO': 0.0,\n",
       "  'BACKBONE': 'pointnet',\n",
       "  'XYZ_UP_LAYER': [128, 128],\n",
       "  'NUM_POINTS': 512,\n",
       "  'SA_CONFIG': {'NPOINTS': [128, 32, -1],\n",
       "   'RADIUS': [0.2, 0.4, 100],\n",
       "   'NSAMPLE': [64, 64, 64],\n",
       "   'MLPS': [[128, 128, 128], [128, 128, 256], [256, 256, 512]]},\n",
       "  'CLS_FC': [256, 256],\n",
       "  'REG_FC': [256, 256],\n",
       "  'LOSS_CLS': 'BinaryCrossEntropy',\n",
       "  'FOCAL_ALPHA': [0.25, 0.75],\n",
       "  'FOCAL_GAMMA': 2.0,\n",
       "  'CLS_WEIGHT': array([1., 1., 1.], dtype=float32),\n",
       "  'CLS_FG_THRESH': 0.6,\n",
       "  'CLS_BG_THRESH': 0.45,\n",
       "  'CLS_BG_THRESH_LO': 0.05,\n",
       "  'REG_FG_THRESH': 0.55,\n",
       "  'FG_RATIO': 0.5,\n",
       "  'ROI_PER_IMAGE': 64,\n",
       "  'HARD_BG_RATIO': 0.8,\n",
       "  'SCORE_THRESH': 0.3,\n",
       "  'NMS_THRESH': 0.1},\n",
       " 'TRAIN': {'SPLIT': 'train',\n",
       "  'VAL_SPLIT': 'smallval',\n",
       "  'LR': 0.002,\n",
       "  'LR_CLIP': 1e-05,\n",
       "  'LR_DECAY': 0.5,\n",
       "  'DECAY_STEP_LIST': [100, 150, 180, 200],\n",
       "  'LR_WARMUP': True,\n",
       "  'WARMUP_MIN': 0.0002,\n",
       "  'WARMUP_EPOCH': 1,\n",
       "  'BN_MOMENTUM': 0.1,\n",
       "  'BN_DECAY': 0.5,\n",
       "  'BNM_CLIP': 0.01,\n",
       "  'BN_DECAY_STEP_LIST': [1000],\n",
       "  'OPTIMIZER': 'adam_onecycle',\n",
       "  'WEIGHT_DECAY': 0.001,\n",
       "  'MOMENTUM': 0.9,\n",
       "  'MOMS': [0.95, 0.85],\n",
       "  'DIV_FACTOR': 10.0,\n",
       "  'PCT_START': 0.4,\n",
       "  'GRAD_NORM_CLIP': 1.0,\n",
       "  'RPN_PRE_NMS_TOP_N': 9000,\n",
       "  'RPN_POST_NMS_TOP_N': 512,\n",
       "  'RPN_NMS_THRESH': 0.85,\n",
       "  'RPN_DISTANCE_BASED_PROPOSE': True},\n",
       " 'TEST': {'SPLIT': 'val',\n",
       "  'RPN_PRE_NMS_TOP_N': 9000,\n",
       "  'RPN_POST_NMS_TOP_N': 100,\n",
       "  'RPN_NMS_THRESH': 0.8,\n",
       "  'RPN_DISTANCE_BASED_PROPOSE': True}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_one_epoch(model, dataloader, epoch_id, result_dir, logger):\n",
    "    if cfg.RPN.ENABLED and not cfg.RCNN.ENABLED:\n",
    "        print('-------------eval_one_epoch_rpn-------------------')\n",
    "        ret_dict = eval_one_epoch_rpn(model, dataloader, epoch_id, result_dir, logger)\n",
    "    elif not cfg.RPN.ENABLED and cfg.RCNN.ENABLED:\n",
    "        print('-------------eval_one_epoch_rcnn-------------------')\n",
    "        ret_dict = eval_one_epoch_rcnn(model, dataloader, epoch_id, result_dir, logger)\n",
    "    elif cfg.RPN.ENABLED and cfg.RCNN.ENABLED:\n",
    "        print('-------------eval_one_epoch_joint-------------------')\n",
    "        ret_dict = eval_one_epoch_joint(model, dataloader, epoch_id, result_dir, logger)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return ret_dict\n",
    "\n",
    "def eval_single_ckpt(root_result_dir):\n",
    "    root_result_dir = os.path.join(root_result_dir, 'eval')\n",
    "    # set epoch_id and output dir\n",
    "    num_list = re.findall(r'\\d+', args.ckpt) if args.ckpt is not None else []\n",
    "    epoch_id = num_list[-1] if num_list.__len__() > 0 else 'no_number'\n",
    "    root_result_dir = os.path.join(root_result_dir, 'epoch_%s' % epoch_id, cfg.TEST.SPLIT)\n",
    "    if args.test:\n",
    "        root_result_dir = os.path.join(root_result_dir, 'test_mode')\n",
    "\n",
    "    if args.extra_tag != 'default':\n",
    "        root_result_dir = os.path.join(root_result_dir, args.extra_tag)\n",
    "    os.makedirs(root_result_dir, exist_ok=True)\n",
    "\n",
    "    log_file = os.path.join(root_result_dir, 'log_eval_one.txt')\n",
    "    logger = create_logger(log_file)\n",
    "#     logger.info('**********************Start logging**********************')\n",
    "#     for key, val in vars(args).items():\n",
    "#         logger.info(\"{:16} {}\".format(key, val))\n",
    "    save_config_to_file(cfg, logger=logger)\n",
    "#     print(logger)\n",
    "    # create dataloader & network\n",
    "    test_loader = create_dataloader(logger)\n",
    "    model = PointRCNN(num_classes=test_loader.dataset.num_class, use_xyz=True, mode='TEST')\n",
    "    model.cuda()\n",
    "\n",
    "    # copy important files to backup\n",
    "    backup_dir = os.path.join(root_result_dir, 'backup_files')\n",
    "    os.makedirs(backup_dir, exist_ok=True)\n",
    "    os.system('cp *.py %s/' % backup_dir)\n",
    "    os.system('cp ../lib/net/*.py %s/' % backup_dir)\n",
    "    os.system('cp ../lib/datasets/kitti_rcnn_dataset.py %s/' % backup_dir)\n",
    "\n",
    "    # load checkpoint\n",
    "    load_ckpt_based_on_args(model, logger)\n",
    "\n",
    "    # start evaluation\n",
    "#     eval_one_epoch(model, test_loader, epoch_id, root_result_dir, logger)\n",
    "    \n",
    "    return model, test_loader, epoch_id, root_result_dir, logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../output/rcnn/default'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_result_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-17 16:25:06,327   INFO  Load testing samples from ../data/KITTI/object/training\n",
      "2020-10-17 16:25:06,328   INFO  Done: total test samples 3769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-17 16:25:09,089   INFO  ==> Loading from checkpoint 'PointRCNN.pth'\n",
      "2020-10-17 16:25:09,143   INFO  ==> Done\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model, test_loader, epoch_id, root_result_dir, logger = eval_single_ckpt(root_result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = root_result_dir\n",
    "dataloader = test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-17 16:25:11,146   INFO  ---- EPOCH no_number JOINT EVALUATION ----\n",
      "2020-10-17 16:25:11,147   INFO  ==> Output file: ../output/rcnn/default/eval/epoch_no_number/val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN_SIZE---- tensor([1.5256, 1.6286, 3.8831], device='cuda:0')\n",
      "mode---- EVAL\n",
      "final_output_dir---- ../output/rcnn/default/eval/epoch_no_number/val/final_result/data\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(666)\n",
    "MEAN_SIZE = torch.from_numpy(cfg.CLS_MEAN_SIZE[0]).cuda()\n",
    "print('MEAN_SIZE----', MEAN_SIZE)\n",
    "mode = 'TEST' if args.test else 'EVAL'\n",
    "print('mode----', mode)\n",
    "final_output_dir = os.path.join(result_dir, 'final_result', 'data')\n",
    "os.makedirs(final_output_dir, exist_ok=True)\n",
    "print('final_output_dir----', final_output_dir)\n",
    "\n",
    "if args.save_result:\n",
    "    roi_output_dir = os.path.join(result_dir, 'roi_result', 'data')\n",
    "    refine_output_dir = os.path.join(result_dir, 'refine_result', 'data')\n",
    "    rpn_output_dir = os.path.join(result_dir, 'rpn_result', 'data')\n",
    "    os.makedirs(rpn_output_dir, exist_ok=True)\n",
    "    os.makedirs(roi_output_dir, exist_ok=True)\n",
    "    os.makedirs(refine_output_dir, exist_ok=True)\n",
    "\n",
    "logger.info('---- EPOCH %s JOINT EVALUATION ----' % epoch_id)\n",
    "logger.info('==> Output file: %s' % result_dir)\n",
    "model.eval()\n",
    "\n",
    "thresh_list = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "total_recalled_bbox_list, total_gt_bbox = [0] * 5, 0\n",
    "total_roi_recalled_bbox_list = [0] * 5\n",
    "dataset = dataloader.dataset\n",
    "cnt = final_total = total_cls_acc = total_cls_acc_refined = total_rpn_iou = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "eval:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "progress_bar = tqdm.tqdm(total=1, leave=True, desc='eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 1/1 [00:01<00:00,  1.01s/it, mode=EVAL, recall=0/2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roi_boxes3d--- torch.Size([1, 100, 7])\n",
      "rcnn_reg--- torch.Size([1, 100, 46])\n",
      "cfg.RCNN.LOC_SCOPE--- 1.5\n",
      "cfg.RCNN.LOC_BIN_SIZE--- 0.5\n",
      "pred_boxes3d--- torch.Size([1, 100, 7])\n",
      "rcnn_cls--- torch.Size([1, 100, 1])\n",
      "torch.Size([1, 100, 1])\n",
      "0\n",
      "cur_gt_boxes3d------ (1, 7) 0\n",
      "pred_boxes3d[k]----- torch.Size([100, 7])\n",
      "iou3d----- torch.Size([100, 1])\n",
      "total_recalled_bbox_list---- [2, 2, 2, 0, 0]\n",
      "total_roi_recalled_bbox_list---- [2, 2, 2, 2, 0]\n",
      "pred_boxes3d_selected---- torch.Size([9, 7])\n",
      "raw_scores_selected---- torch.Size([9, 1])\n",
      "norm_scores_selected---- torch.Size([9, 1])\n",
      "keep_idx---- torch.Size([4])\n",
      "pred_boxes3d_selected---- (4, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    \n",
    "# for data in dataloader:\n",
    "    data = next(iter(dataloader))\n",
    "    cnt += 1\n",
    "    sample_id, pts_rect, pts_features, pts_input = \\\n",
    "        data['sample_id'], data['pts_rect'], data['pts_features'], data['pts_input']\n",
    "    batch_size = len(sample_id)\n",
    "    inputs = torch.from_numpy(pts_input).cuda(non_blocking=True).float()\n",
    "    input_data = {'pts_input': inputs}\n",
    "\n",
    "    # model inference\n",
    "    ret_dict = model(input_data)\n",
    "    \n",
    "    roi_scores_raw = ret_dict['roi_scores_raw']  # (B, M)\n",
    "    roi_boxes3d = ret_dict['rois']  # (B, M, 7)\n",
    "    seg_result = ret_dict['seg_result'].long()  # (B, N)\n",
    "\n",
    "    rcnn_cls = ret_dict['rcnn_cls'].view(batch_size, -1, ret_dict['rcnn_cls'].shape[1])\n",
    "    rcnn_reg = ret_dict['rcnn_reg'].view(batch_size, -1, ret_dict['rcnn_reg'].shape[1])  # (B, M, C)\n",
    "\n",
    "    # bounding box regression\n",
    "    anchor_size = MEAN_SIZE\n",
    "    if cfg.RCNN.SIZE_RES_ON_ROI:\n",
    "        assert False\n",
    "    print('roi_boxes3d---', roi_boxes3d.shape)\n",
    "    print('rcnn_reg---', rcnn_reg.shape)\n",
    "    pred_boxes3d = decode_bbox_target(roi_boxes3d.view(-1, 7), rcnn_reg.view(-1, rcnn_reg.shape[-1]),\n",
    "                                      anchor_size=anchor_size,\n",
    "                                      loc_scope=cfg.RCNN.LOC_SCOPE,\n",
    "                                      loc_bin_size=cfg.RCNN.LOC_BIN_SIZE,\n",
    "                                      num_head_bin=cfg.RCNN.NUM_HEAD_BIN,\n",
    "                                      get_xz_fine=True, get_y_by_bin=cfg.RCNN.LOC_Y_BY_BIN,\n",
    "                                      loc_y_scope=cfg.RCNN.LOC_Y_SCOPE, loc_y_bin_size=cfg.RCNN.LOC_Y_BIN_SIZE,\n",
    "                                      get_ry_fine=True).view(batch_size, -1, 7)\n",
    "    print('cfg.RCNN.LOC_SCOPE---', cfg.RCNN.LOC_SCOPE)\n",
    "    print('cfg.RCNN.LOC_BIN_SIZE---', cfg.RCNN.LOC_BIN_SIZE)\n",
    "    print('pred_boxes3d---', pred_boxes3d.shape)\n",
    "    \n",
    "    print('rcnn_cls---', rcnn_cls.shape)\n",
    "    # scoring\n",
    "    if rcnn_cls.shape[2] == 1:\n",
    "        raw_scores = rcnn_cls  # (B, M, 1)\n",
    "\n",
    "        norm_scores = torch.sigmoid(raw_scores)\n",
    "        pred_classes = (norm_scores > cfg.RCNN.SCORE_THRESH).long()\n",
    "    else:\n",
    "        pred_classes = torch.argmax(rcnn_cls, dim=1).view(-1)\n",
    "        cls_norm_scores = F.softmax(rcnn_cls, dim=1)\n",
    "        raw_scores = rcnn_cls[:, pred_classes]\n",
    "        norm_scores = cls_norm_scores[:, pred_classes]\n",
    "    print(pred_classes.shape)\n",
    "    # evaluation\n",
    "    recalled_num = gt_num = rpn_iou = 0\n",
    "    if not args.test:\n",
    "        if not cfg.RPN.FIXED:\n",
    "            rpn_cls_label, rpn_reg_label = data['rpn_cls_label'], data['rpn_reg_label']\n",
    "            rpn_cls_label = torch.from_numpy(rpn_cls_label).cuda(non_blocking=True).long()\n",
    "\n",
    "        gt_boxes3d = data['gt_boxes3d']\n",
    "\n",
    "        for k in range(batch_size):\n",
    "            # calculate recall\n",
    "            print(k)\n",
    "            cur_gt_boxes3d = gt_boxes3d[k]\n",
    "            tmp_idx = cur_gt_boxes3d.__len__() - 1\n",
    "            print('cur_gt_boxes3d------', cur_gt_boxes3d.shape, tmp_idx)\n",
    "            while tmp_idx >= 0 and cur_gt_boxes3d[tmp_idx].sum() == 0:\n",
    "                tmp_idx -= 1\n",
    "\n",
    "            if tmp_idx >= 0:\n",
    "                cur_gt_boxes3d = cur_gt_boxes3d[:tmp_idx + 1]\n",
    "\n",
    "                cur_gt_boxes3d = torch.from_numpy(cur_gt_boxes3d).cuda(non_blocking=True).float()\n",
    "                print('pred_boxes3d[k]-----', pred_boxes3d[k].shape)\n",
    "                iou3d = iou3d_utils.boxes_iou3d_gpu(pred_boxes3d[k], cur_gt_boxes3d)\n",
    "                \n",
    "                print('iou3d-----', iou3d.shape)\n",
    "                \n",
    "                gt_max_iou, _ = iou3d.max(dim=0)\n",
    "                refined_iou, _ = iou3d.max(dim=1)\n",
    "\n",
    "                for idx, thresh in enumerate(thresh_list):\n",
    "                    total_recalled_bbox_list[idx] += (gt_max_iou > thresh).sum().item()\n",
    "                recalled_num += (gt_max_iou > 0.7).sum().item()\n",
    "                gt_num += cur_gt_boxes3d.shape[0]\n",
    "                total_gt_bbox += cur_gt_boxes3d.shape[0]\n",
    "\n",
    "                # original recall\n",
    "                iou3d_in = iou3d_utils.boxes_iou3d_gpu(roi_boxes3d[k], cur_gt_boxes3d)\n",
    "                gt_max_iou_in, _ = iou3d_in.max(dim=0)\n",
    "\n",
    "                for idx, thresh in enumerate(thresh_list):\n",
    "                    total_roi_recalled_bbox_list[idx] += (gt_max_iou_in > thresh).sum().item()\n",
    "                \n",
    "                print('total_recalled_bbox_list----', total_recalled_bbox_list)\n",
    "                print('total_roi_recalled_bbox_list----', total_roi_recalled_bbox_list)\n",
    "                \n",
    "            if not cfg.RPN.FIXED:\n",
    "                fg_mask = rpn_cls_label > 0\n",
    "                correct = ((seg_result == rpn_cls_label) & fg_mask).sum().float()\n",
    "                union = fg_mask.sum().float() + (seg_result > 0).sum().float() - correct\n",
    "                rpn_iou = correct / torch.clamp(union, min=1.0)\n",
    "                total_rpn_iou += rpn_iou.item()\n",
    "\n",
    "    disp_dict = {'mode': mode, 'recall': '%d/%d' % (total_recalled_bbox_list[3], total_gt_bbox)}\n",
    "    progress_bar.set_postfix(disp_dict)\n",
    "    progress_bar.update()\n",
    "\n",
    "    if args.save_result:\n",
    "        # save roi and refine results\n",
    "        roi_boxes3d_np = roi_boxes3d.cpu().numpy()\n",
    "        pred_boxes3d_np = pred_boxes3d.cpu().numpy()\n",
    "        roi_scores_raw_np = roi_scores_raw.cpu().numpy()\n",
    "        raw_scores_np = raw_scores.cpu().numpy()\n",
    "\n",
    "        rpn_cls_np = ret_dict['rpn_cls'].cpu().numpy()\n",
    "        rpn_xyz_np = ret_dict['backbone_xyz'].cpu().numpy()\n",
    "        seg_result_np = seg_result.cpu().numpy()\n",
    "        output_data = np.concatenate((rpn_xyz_np, rpn_cls_np.reshape(batch_size, -1, 1),\n",
    "                                      seg_result_np.reshape(batch_size, -1, 1)), axis=2)\n",
    "\n",
    "        for k in range(batch_size):\n",
    "            cur_sample_id = sample_id[k]\n",
    "            calib = dataset.get_calib(cur_sample_id)\n",
    "            image_shape = dataset.get_image_shape(cur_sample_id)\n",
    "            save_kitti_format(cur_sample_id, calib, roi_boxes3d_np[k], roi_output_dir,\n",
    "                              roi_scores_raw_np[k], image_shape)\n",
    "            save_kitti_format(cur_sample_id, calib, pred_boxes3d_np[k], refine_output_dir,\n",
    "                              raw_scores_np[k], image_shape)\n",
    "\n",
    "            output_file = os.path.join(rpn_output_dir, '%06d.npy' % cur_sample_id)\n",
    "            np.save(output_file, output_data.astype(np.float32))\n",
    "\n",
    "    # scores thresh\n",
    "    inds = norm_scores > cfg.RCNN.SCORE_THRESH\n",
    "\n",
    "    for k in range(batch_size):\n",
    "        cur_inds = inds[k].view(-1)\n",
    "        if cur_inds.sum() == 0:\n",
    "            continue\n",
    "\n",
    "        pred_boxes3d_selected = pred_boxes3d[k, cur_inds]\n",
    "        raw_scores_selected = raw_scores[k, cur_inds]\n",
    "        norm_scores_selected = norm_scores[k, cur_inds]\n",
    "        \n",
    "        print('pred_boxes3d_selected----', pred_boxes3d_selected.shape)\n",
    "        print('raw_scores_selected----', raw_scores_selected.shape)\n",
    "        print('norm_scores_selected----', norm_scores_selected.shape)\n",
    "        # NMS thresh\n",
    "        # rotated nms\n",
    "        boxes_bev_selected = kitti_utils.boxes3d_to_bev_torch(pred_boxes3d_selected)\n",
    "        keep_idx = iou3d_utils.nms_gpu(boxes_bev_selected, raw_scores_selected, cfg.RCNN.NMS_THRESH).view(-1)\n",
    "        \n",
    "        print('keep_idx----', keep_idx.shape)\n",
    "        pred_boxes3d_selected = pred_boxes3d_selected[keep_idx]\n",
    "        scores_selected = raw_scores_selected[keep_idx]\n",
    "        pred_boxes3d_selected, scores_selected = pred_boxes3d_selected.cpu().numpy(), scores_selected.cpu().numpy()\n",
    "        print('pred_boxes3d_selected----', pred_boxes3d_selected.shape)\n",
    "        \n",
    "        cur_sample_id = sample_id[k]\n",
    "        calib = dataset.get_calib(cur_sample_id)\n",
    "        final_total += pred_boxes3d_selected.shape[0]\n",
    "        image_shape = dataset.get_image_shape(cur_sample_id)\n",
    "        save_kitti_format(cur_sample_id, calib, pred_boxes3d_selected, final_output_dir, scores_selected, image_shape)\n",
    "\n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " <lib.utils.calibration.Calibration at 0x7f6116db8eb8>,\n",
       " array([[  7.0501876,   1.2009901,  29.781366 ,   1.5461532,   1.6425707,\n",
       "           3.9844525,  -1.5398288],\n",
       "        [-16.425415 ,   2.401994 ,  58.772903 ,   1.4734521,   1.5792282,\n",
       "           3.8998787,  -1.6058664],\n",
       "        [-23.394703 ,   2.3451226,  50.424824 ,   1.4398   ,   1.5592022,\n",
       "           3.5853415,   1.6087191],\n",
       "        [  3.5157132,   1.4888533,  29.091475 ,   1.476376 ,   1.6119881,\n",
       "           3.950966 ,  -1.5695319]], dtype=float32),\n",
       " '../output/rcnn/default/eval/epoch_no_number/val/final_result/data',\n",
       " array([[ 1.6345751 ],\n",
       "        [ 1.224974  ],\n",
       "        [ 0.33123755],\n",
       "        [-0.81588537]], dtype=float32),\n",
       " (375, 1242, 3))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_sample_id, calib, pred_boxes3d_selected, final_output_dir, scores_selected, image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]]], device='cuda:0', dtype=torch.uint8)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sample_id', 'random_select', 'pts_input', 'pts_rect', 'pts_features', 'gt_boxes3d'])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['rpn_cls', 'rpn_reg', 'backbone_xyz', 'backbone_features', 'rois', 'roi_scores_raw', 'seg_result', 'rcnn_cls', 'rcnn_reg'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 16384, 1]),\n",
       " torch.Size([1, 16384, 52]),\n",
       " torch.Size([1, 16384, 3]),\n",
       " torch.Size([1, 128, 16384]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_dict['rpn_cls'].shape,ret_dict['rpn_reg'].shape,ret_dict['backbone_xyz'].shape,ret_dict['backbone_features'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 100, 7]),\n",
       " torch.Size([1, 100]),\n",
       " torch.Size([1, 16384]),\n",
       " torch.Size([100, 1]),\n",
       " torch.Size([100, 46]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_dict['rois'].shape,ret_dict['roi_scores_raw'].shape,ret_dict['seg_result'].shape,ret_dict['rcnn_cls'].shape,ret_dict['rcnn_reg'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-17 16:27:55,092   INFO  -------------------performance of epoch no_number---------------------\n",
      "2020-10-17 16:27:55,093   INFO  2020-10-17 16:27:55.093166\n",
      "2020-10-17 16:27:55,094   INFO  final average detections: 0.001\n",
      "2020-10-17 16:27:55,095   INFO  final average rpn_iou refined: 0.000\n",
      "2020-10-17 16:27:55,096   INFO  final average cls acc: 0.000\n",
      "2020-10-17 16:27:55,097   INFO  final average cls acc refined: 0.000\n",
      "2020-10-17 16:27:55,098   INFO  total roi bbox recall(thresh=0.100): 2 / 2 = 1.000000\n",
      "2020-10-17 16:27:55,099   INFO  total roi bbox recall(thresh=0.300): 2 / 2 = 1.000000\n",
      "2020-10-17 16:27:55,100   INFO  total roi bbox recall(thresh=0.500): 2 / 2 = 1.000000\n",
      "2020-10-17 16:27:55,100   INFO  total roi bbox recall(thresh=0.700): 2 / 2 = 1.000000\n",
      "2020-10-17 16:27:55,101   INFO  total roi bbox recall(thresh=0.900): 0 / 2 = 0.000000\n",
      "2020-10-17 16:27:55,102   INFO  total bbox recall(thresh=0.100): 2 / 2 = 1.000000\n",
      "2020-10-17 16:27:55,102   INFO  total bbox recall(thresh=0.300): 2 / 2 = 1.000000\n",
      "2020-10-17 16:27:55,103   INFO  total bbox recall(thresh=0.500): 2 / 2 = 1.000000\n",
      "2020-10-17 16:27:55,103   INFO  total bbox recall(thresh=0.700): 0 / 2 = 0.000000\n",
      "2020-10-17 16:27:55,104   INFO  total bbox recall(thresh=0.900): 0 / 2 = 0.000000\n",
      "2020-10-17 16:27:55,107   INFO  Averate Precision:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.label_dir----- ../data/KITTI/object/training/label_2\n",
      "final_output_dir----- ../output/rcnn/default/eval/epoch_no_number/val/final_result/data\n",
      "split_file----- /home/congcong/FLAG/basenet/PointRCNN/data/KITTI/ImageSets/val.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-17 16:27:59,783   INFO  Car AP@0.70, 0.70, 0.70:\n",
      "bbox AP:96.9112, 89.5387, 88.7494\n",
      "bev  AP:90.2194, 87.8969, 85.5214\n",
      "3d   AP:89.1975, 78.8578, 77.9157\n",
      "aos  AP:96.90, 89.42, 88.55\n",
      "Car AP@0.70, 0.50, 0.50:\n",
      "bbox AP:96.9112, 89.5387, 88.7494\n",
      "bev  AP:97.0926, 89.8168, 89.3443\n",
      "3d   AP:97.0529, 89.7747, 89.2549\n",
      "aos  AP:96.90, 89.42, 88.55\n",
      "\n",
      "2020-10-17 16:27:59,785   INFO  result is saved to: ../output/rcnn/default/eval/epoch_no_number/val\n"
     ]
    }
   ],
   "source": [
    "# dump empty files\n",
    "split_file = os.path.join(dataset.imageset_dir, '..', '..', 'ImageSets', dataset.split + '.txt')\n",
    "split_file = os.path.abspath(split_file)\n",
    "image_idx_list = [x.strip() for x in open(split_file).readlines()]\n",
    "empty_cnt = 0\n",
    "for k in range(image_idx_list.__len__()):\n",
    "    cur_file = os.path.join(final_output_dir, '%s.txt' % image_idx_list[k])\n",
    "    if not os.path.exists(cur_file):\n",
    "        with open(cur_file, 'w') as temp_f:\n",
    "            pass\n",
    "        empty_cnt += 1\n",
    "        logger.info('empty_cnt=%d: dump empty file %s' % (empty_cnt, cur_file))\n",
    "\n",
    "ret_dict = {'empty_cnt': empty_cnt}\n",
    "\n",
    "logger.info('-------------------performance of epoch %s---------------------' % epoch_id)\n",
    "logger.info(str(datetime.now()))\n",
    "\n",
    "avg_rpn_iou = (total_rpn_iou / max(cnt, 1.0))\n",
    "avg_cls_acc = (total_cls_acc / max(cnt, 1.0))\n",
    "avg_cls_acc_refined = (total_cls_acc_refined / max(cnt, 1.0))\n",
    "avg_det_num = (final_total / max(len(dataset), 1.0))\n",
    "logger.info('final average detections: %.3f' % avg_det_num)\n",
    "logger.info('final average rpn_iou refined: %.3f' % avg_rpn_iou)\n",
    "logger.info('final average cls acc: %.3f' % avg_cls_acc)\n",
    "logger.info('final average cls acc refined: %.3f' % avg_cls_acc_refined)\n",
    "ret_dict['rpn_iou'] = avg_rpn_iou\n",
    "ret_dict['rcnn_cls_acc'] = avg_cls_acc\n",
    "ret_dict['rcnn_cls_acc_refined'] = avg_cls_acc_refined\n",
    "ret_dict['rcnn_avg_num'] = avg_det_num\n",
    "\n",
    "for idx, thresh in enumerate(thresh_list):\n",
    "    cur_roi_recall = total_roi_recalled_bbox_list[idx] / max(total_gt_bbox, 1.0)\n",
    "    logger.info('total roi bbox recall(thresh=%.3f): %d / %d = %f' % (thresh, total_roi_recalled_bbox_list[idx],\n",
    "                                                                      total_gt_bbox, cur_roi_recall))\n",
    "    ret_dict['rpn_recall(thresh=%.2f)' % thresh] = cur_roi_recall\n",
    "\n",
    "for idx, thresh in enumerate(thresh_list):\n",
    "    cur_recall = total_recalled_bbox_list[idx] / max(total_gt_bbox, 1.0)\n",
    "    logger.info('total bbox recall(thresh=%.3f): %d / %d = %f' % (thresh, total_recalled_bbox_list[idx],\n",
    "                                                                  total_gt_bbox, cur_recall))\n",
    "    ret_dict['rcnn_recall(thresh=%.2f)' % thresh] = cur_recall\n",
    "\n",
    "if cfg.TEST.SPLIT != 'test':\n",
    "    logger.info('Averate Precision:')\n",
    "    name_to_class = {'Car': 0, 'Pedestrian': 1, 'Cyclist': 2}\n",
    "    print('dataset.label_dir-----', dataset.label_dir)\n",
    "    print('final_output_dir-----', final_output_dir)\n",
    "    print('split_file-----', split_file)\n",
    "    ap_result_str, ap_dict = kitti_evaluate(dataset.label_dir, final_output_dir, label_split_file=split_file,\n",
    "                                            current_class=name_to_class[cfg.CLASSES])\n",
    "    logger.info(ap_result_str)\n",
    "    ret_dict.update(ap_dict)\n",
    "\n",
    "logger.info('result is saved to: %s' % result_dir)\n",
    "# return ret_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Car AP@0.70, 0.70, 0.70:\n",
      "bbox AP:96.9112, 89.5387, 88.7494\n",
      "bev  AP:90.2194, 87.8969, 85.5214\n",
      "3d   AP:89.1975, 78.8578, 77.9157\n",
      "aos  AP:96.90, 89.42, 88.55\n",
      "Car AP@0.70, 0.50, 0.50:\n",
      "bbox AP:96.9112, 89.5387, 88.7494\n",
      "bev  AP:97.0926, 89.8168, 89.3443\n",
      "3d   AP:97.0529, 89.7747, 89.2549\n",
      "aos  AP:96.90, 89.42, 88.55\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ap_result_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Car_3d_easy': 89.19749657709211, 'Car_3d_moderate': 78.85779143565469, 'Car_3d_hard': 77.91573735808278, 'Car_bev_easy': 90.21938602789402, 'Car_bev_moderate': 87.89694105559707, 'Car_bev_hard': 85.52137509159714, 'Car_image_easy': 96.91116515724126, 'Car_image_moderate': 89.53871256023108, 'Car_image_hard': 88.74943810167436}\n"
     ]
    }
   ],
   "source": [
    "print(ap_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_id, pts_rect, pts_features, pts_input = data['sample_id'], data['pts_rect'], data['pts_features'], data['pts_input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1], dtype=int32),\n",
       " array([[[  8.222908  ,  -0.11173396,  20.899475  ],\n",
       "         [  4.342349  ,   1.4550459 ,   5.649181  ],\n",
       "         [  3.5463061 ,   1.4802692 ,  11.563428  ],\n",
       "         ...,\n",
       "         [  3.4898777 ,   1.3948839 ,   7.356103  ],\n",
       "         [  1.5233301 ,   1.6571573 ,  13.716171  ],\n",
       "         [-24.178858  ,   0.27927884,  44.31227   ]]], dtype=float32),\n",
       " array([[[-0.05000001],\n",
       "         [-0.11000001],\n",
       "         [-0.18      ],\n",
       "         ...,\n",
       "         [-0.3       ],\n",
       "         [-0.22      ],\n",
       "         [-0.5       ]]], dtype=float32),\n",
       " array([[[  8.222908  ,  -0.11173396,  20.899475  ],\n",
       "         [  4.342349  ,   1.4550459 ,   5.649181  ],\n",
       "         [  3.5463061 ,   1.4802692 ,  11.563428  ],\n",
       "         ...,\n",
       "         [  3.4898777 ,   1.3948839 ,   7.356103  ],\n",
       "         [  1.5233301 ,   1.6571573 ,  13.716171  ],\n",
       "         [-24.178858  ,   0.27927884,  44.31227   ]]], dtype=float32))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_id, pts_rect, pts_features, pts_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 16384, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pts_rect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 16384, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pts_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 16384, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pts_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sample_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sample_id': array([1], dtype=int32),\n",
       " 'random_select': array([1], dtype=int32),\n",
       " 'pts_input': array([[[  8.222908  ,  -0.11173396,  20.899475  ],\n",
       "         [  4.342349  ,   1.4550459 ,   5.649181  ],\n",
       "         [  3.5463061 ,   1.4802692 ,  11.563428  ],\n",
       "         ...,\n",
       "         [  3.4898777 ,   1.3948839 ,   7.356103  ],\n",
       "         [  1.5233301 ,   1.6571573 ,  13.716171  ],\n",
       "         [-24.178858  ,   0.27927884,  44.31227   ]]], dtype=float32),\n",
       " 'pts_rect': array([[[  8.222908  ,  -0.11173396,  20.899475  ],\n",
       "         [  4.342349  ,   1.4550459 ,   5.649181  ],\n",
       "         [  3.5463061 ,   1.4802692 ,  11.563428  ],\n",
       "         ...,\n",
       "         [  3.4898777 ,   1.3948839 ,   7.356103  ],\n",
       "         [  1.5233301 ,   1.6571573 ,  13.716171  ],\n",
       "         [-24.178858  ,   0.27927884,  44.31227   ]]], dtype=float32),\n",
       " 'pts_features': array([[[-0.05000001],\n",
       "         [-0.11000001],\n",
       "         [-0.18      ],\n",
       "         ...,\n",
       "         [-0.3       ],\n",
       "         [-0.22      ],\n",
       "         [-0.5       ]]], dtype=float32),\n",
       " 'gt_boxes3d': array([[[-16.53,   2.39,  58.49,   1.67,   1.87,   3.69,   1.57]]],\n",
       "       dtype=float32)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.save_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-16.53,   2.39,  58.49,   1.67,   1.87,   3.69,   1.57]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['gt_boxes3d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.RPN.FIXED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mode': 'EVAL', 'recall': '0/13'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " <lib.utils.calibration.Calibration at 0x7f6116db8eb8>,\n",
       " array([[  7.0501876,   1.2009901,  29.781366 ,   1.5461532,   1.6425707,\n",
       "           3.9844525,  -1.5398288],\n",
       "        [-16.425415 ,   2.401994 ,  58.772903 ,   1.4734521,   1.5792282,\n",
       "           3.8998787,  -1.6058664],\n",
       "        [-23.394703 ,   2.3451226,  50.424824 ,   1.4398   ,   1.5592022,\n",
       "           3.5853415,   1.6087191],\n",
       "        [  3.5157132,   1.4888533,  29.091475 ,   1.476376 ,   1.6119881,\n",
       "           3.950966 ,  -1.5695319]], dtype=float32),\n",
       " '../output/rcnn/default/eval/epoch_no_number/val/final_result/data',\n",
       " array([[ 1.6345751 ],\n",
       "        [ 1.224974  ],\n",
       "        [ 0.33123755],\n",
       "        [-0.81588537]], dtype=float32),\n",
       " (375, 1242, 3))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_sample_id, calib, pred_boxes3d_selected, final_output_dir, scores_selected, image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_id, calib, bbox3d, kitti_output_dir, scores, img_shape = cur_sample_id, calib, pred_boxes3d_selected, final_output_dir, scores_selected, image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "corners3d = kitti_utils.boxes3d_to_corners3d(bbox3d)\n",
    "img_boxes, _ = calib.corners3d_to_img_boxes(corners3d)\n",
    "\n",
    "img_boxes[:, 0] = np.clip(img_boxes[:, 0], 0, img_shape[1] - 1)\n",
    "img_boxes[:, 1] = np.clip(img_boxes[:, 1], 0, img_shape[0] - 1)\n",
    "img_boxes[:, 2] = np.clip(img_boxes[:, 2], 0, img_shape[1] - 1)\n",
    "img_boxes[:, 3] = np.clip(img_boxes[:, 3], 0, img_shape[0] - 1)\n",
    "\n",
    "img_boxes_w = img_boxes[:, 2] - img_boxes[:, 0]\n",
    "img_boxes_h = img_boxes[:, 3] - img_boxes[:, 1]\n",
    "box_valid_mask = np.logical_and(img_boxes_w < img_shape[1] * 0.8, img_boxes_h < img_shape[0] * 0.8)\n",
    "\n",
    "kitti_output_file = os.path.join(kitti_output_dir, '%06d.txt' % sample_id)\n",
    "with open(kitti_output_file, 'w') as f:\n",
    "    for k in range(bbox3d.shape[0]):\n",
    "        if box_valid_mask[k] == 0:\n",
    "            continue\n",
    "        x, z, ry = bbox3d[k, 0], bbox3d[k, 2], bbox3d[k, 6]\n",
    "        beta = np.arctan2(z, x)\n",
    "        alpha = -np.sign(beta) * np.pi / 2 + beta + ry\n",
    "        print('%s -1 -1 %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f' %(cfg.CLASSES, alpha, img_boxes[k, 0], img_boxes[k, 1], img_boxes[k, 2], img_boxes[k, 3], bbox3d[k, 3], bbox3d[k, 4], bbox3d[k, 5], bbox3d[k, 0], bbox3d[k, 1], bbox3d[k, 2], bbox3d[k, 6], scores[k]), file=f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 8, 3)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corners3d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[753.65511119, 163.87562077, 814.04206835, 204.05249667],\n",
       "       [392.50658303, 183.87782082, 423.749727  , 203.36271303],\n",
       "       [251.02941029, 185.3513199 , 298.65652714, 207.66069765],\n",
       "       [673.93346309, 173.13544474, 726.07559987, 212.45930806]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([753.65511119, 392.50658303, 251.02941029, 673.93346309]), 0, 1241)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_boxes[:, 0], 0, img_shape[1] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  7.0501876,   1.2009901,  29.781366 ,   1.5461532,   1.6425707,\n",
       "          3.9844525,  -1.5398288],\n",
       "       [-16.425415 ,   2.401994 ,  58.772903 ,   1.4734521,   1.5792282,\n",
       "          3.8998787,  -1.6058664],\n",
       "       [-23.394703 ,   2.3451226,  50.424824 ,   1.4398   ,   1.5592022,\n",
       "          3.5853415,   1.6087191],\n",
       "       [  3.5157132,   1.4888533,  29.091475 ,   1.476376 ,   1.6119881,\n",
       "          3.950966 ,  -1.5695319]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_boxes3d_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Car',\n",
       " -1.6897990266468863,\n",
       " 673.9334630942146,\n",
       " 173.13544473855313,\n",
       " 726.0755998686647,\n",
       " 212.45930806290232,\n",
       " 1.476376,\n",
       " 1.6119881,\n",
       " 3.950966,\n",
       " 3.5157132,\n",
       " 1.4888533,\n",
       " 29.091475,\n",
       " -1.5695319,\n",
       " array([-0.81588537], dtype=float32))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.CLASSES, alpha, img_boxes[k, 0], img_boxes[k, 1], img_boxes[k, 2], img_boxes[k, 3], \\\n",
    "bbox3d[k, 3], bbox3d[k, 4], bbox3d[k, 5], bbox3d[k, 0], bbox3d[k, 1], bbox3d[k, 2], bbox3d[k, 6], scores[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Car -1 -1 -1.7723 753.6551 163.8756 814.0421 204.0525 1.5462 1.6426 3.9845 7.0502 1.2010 29.7814 -1.5398 1.6346\n",
    "Car -1 -1 -1.3333 392.5066 183.8778 423.7497 203.3627 1.4735 1.5792 3.8999 -16.4254 2.4020 58.7729 -1.6059 1.2250\n",
    "Car -1 -1 2.0431 251.0294 185.3513 298.6565 207.6607 1.4398 1.5592 3.5853 -23.3947 2.3451 50.4248 1.6087 0.3312\n",
    "Car -1 -1 -1.6898 673.9335 173.1354 726.0756 212.4593 1.4764 1.6120 3.9510 3.5157 1.4889 29.0915 -1.5695 -0.8159"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3d_detection",
   "language": "python",
   "name": "3d_detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
