{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _init_path\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from lib.net.point_rcnn import PointRCNN\n",
    "from lib.datasets.kitti_rcnn_dataset_nuscene import KittiRCNNDataset\n",
    "import tools.train_utils.train_utils as train_utils\n",
    "from lib.utils.bbox_transform import decode_bbox_target\n",
    "from tools.kitti_object_eval_python.evaluate import evaluate as kitti_evaluate\n",
    "\n",
    "from lib.config import cfg, cfg_from_file, save_config_to_file, cfg_from_list\n",
    "import argparse\n",
    "import lib.utils.kitti_utils as kitti_utils\n",
    "import lib.utils.iou3d.iou3d_utils as iou3d_utils\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import re\n",
    "import glob\n",
    "import time\n",
    "from tensorboardX import SummaryWriter\n",
    "import tqdm\n",
    "\n",
    "\n",
    "np.random.seed(1024)  # set the same seed\n",
    "\n",
    "# parser = argparse.ArgumentParser(description=\"arg parser\")\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--cfg_file', type=str, default='cfgs/default.yml', help='specify the config for evaluation')\n",
    "parser.add_argument(\"--eval_mode\", type=str, default='rpn', help=\"specify the evaluation mode\")\n",
    "\n",
    "parser.add_argument('--eval_all', action='store_true', default=False, help='whether to evaluate all checkpoints')\n",
    "parser.add_argument('--test', action='store_true', default=False, help='evaluate without ground truth')\n",
    "parser.add_argument(\"--ckpt\", type=str, default=None, help=\"specify a checkpoint to be evaluated\")\n",
    "parser.add_argument(\"--rpn_ckpt\", type=str, default=None, help=\"specify the checkpoint of rpn if trained separated\")\n",
    "parser.add_argument(\"--rcnn_ckpt\", type=str, default=None, help=\"specify the checkpoint of rcnn if trained separated\")\n",
    "\n",
    "parser.add_argument('--batch_size', type=int, default=1, help='batch size for evaluation')\n",
    "parser.add_argument('--workers', type=int, default=4, help='number of workers for dataloader')\n",
    "parser.add_argument(\"--extra_tag\", type=str, default='nuscenes', help=\"extra tag for multiple evaluation\")\n",
    "parser.add_argument('--output_dir', type=str, default=None, help='specify an output directory if needed')\n",
    "parser.add_argument(\"--ckpt_dir\", type=str, default=None, help=\"specify a ckpt directory to be evaluated if needed\")\n",
    "\n",
    "parser.add_argument('--save_result', action='store_true', default=False, help='save evaluation results to files')\n",
    "parser.add_argument('--save_rpn_feature', action='store_true', default=False,\n",
    "                    help='save features for separately rcnn training and evaluation')\n",
    "\n",
    "parser.add_argument('--random_select', action='store_true', default=True, help='sample to the same number of points')\n",
    "parser.add_argument('--start_epoch', default=0, type=int, help='ignore the checkpoint smaller than this epoch')\n",
    "parser.add_argument(\"--rcnn_eval_roi_dir\", type=str, default=None,\n",
    "                    help='specify the saved rois for rcnn evaluation when using rcnn_offline mode')\n",
    "parser.add_argument(\"--rcnn_eval_feature_dir\", type=str, default=None,\n",
    "                    help='specify the saved features for rcnn evaluation when using rcnn_offline mode')\n",
    "parser.add_argument('--set', dest='set_cfgs', default=None, nargs=argparse.REMAINDER,\n",
    "                    help='set extra config keys if needed')\n",
    "args = parser.parse_args(args=['--cfg_file', 'cfgs/default.yaml', '--ckpt', 'PointRCNN.pth', '--batch_size', '1', '--eval_mode', 'rcnn', '--set', 'RPN.LOC_XZ_FINE', 'False'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_logger(log_file):\n",
    "    log_format = '%(asctime)s  %(levelname)5s  %(message)s'\n",
    "    logging.basicConfig(level=logging.INFO, format=log_format, filename=log_file)\n",
    "    console = logging.StreamHandler()\n",
    "    console.setLevel(logging.INFO)\n",
    "    console.setFormatter(logging.Formatter(log_format))\n",
    "    logging.getLogger(__name__).addHandler(console)\n",
    "    return logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def save_kitti_format(sample_id, calib, bbox3d, kitti_output_dir, scores, img_shape):\n",
    "    corners3d = kitti_utils.boxes3d_to_corners3d(bbox3d)\n",
    "    img_boxes, _ = calib.corners3d_to_img_boxes(corners3d)\n",
    "\n",
    "    img_boxes[:, 0] = np.clip(img_boxes[:, 0], 0, img_shape[1] - 1)\n",
    "    img_boxes[:, 1] = np.clip(img_boxes[:, 1], 0, img_shape[0] - 1)\n",
    "    img_boxes[:, 2] = np.clip(img_boxes[:, 2], 0, img_shape[1] - 1)\n",
    "    img_boxes[:, 3] = np.clip(img_boxes[:, 3], 0, img_shape[0] - 1)\n",
    "\n",
    "    img_boxes_w = img_boxes[:, 2] - img_boxes[:, 0]\n",
    "    img_boxes_h = img_boxes[:, 3] - img_boxes[:, 1]\n",
    "    box_valid_mask = np.logical_and(img_boxes_w < img_shape[1] * 0.8, img_boxes_h < img_shape[0] * 0.8)\n",
    "\n",
    "    kitti_output_file = os.path.join(kitti_output_dir, '%06d.txt' % sample_id)\n",
    "    with open(kitti_output_file, 'w') as f:\n",
    "        for k in range(bbox3d.shape[0]):\n",
    "            if box_valid_mask[k] == 0:\n",
    "                continue\n",
    "            x, z, ry = bbox3d[k, 0], bbox3d[k, 2], bbox3d[k, 6]\n",
    "            beta = np.arctan2(z, x)\n",
    "            alpha = -np.sign(beta) * np.pi / 2 + beta + ry\n",
    "            print('%s -1 -1 %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f' %(cfg.CLASSES, alpha, img_boxes[k, 0], img_boxes[k, 1], img_boxes[k, 2], img_boxes[k, 3], bbox3d[k, 3], bbox3d[k, 4], bbox3d[k, 5], bbox3d[k, 0], bbox3d[k, 1], bbox3d[k, 2], bbox3d[k, 6], scores[k]), file=f)\n",
    "\n",
    "def save_rpn_features(seg_result, rpn_scores_raw, pts_features, backbone_xyz, backbone_features, kitti_features_dir,\n",
    "                      sample_id):\n",
    "    pts_intensity = pts_features[:, 0]\n",
    "\n",
    "    output_file = os.path.join(kitti_features_dir, '%06d.npy' % sample_id)\n",
    "    xyz_file = os.path.join(kitti_features_dir, '%06d_xyz.npy' % sample_id)\n",
    "    seg_file = os.path.join(kitti_features_dir, '%06d_seg.npy' % sample_id)\n",
    "    intensity_file = os.path.join(kitti_features_dir, '%06d_intensity.npy' % sample_id)\n",
    "    np.save(output_file, backbone_features)\n",
    "    np.save(xyz_file, backbone_xyz)\n",
    "    np.save(seg_file, seg_result)\n",
    "    np.save(intensity_file, pts_intensity)\n",
    "    rpn_scores_raw_file = os.path.join(kitti_features_dir, '%06d_rawscore.npy' % sample_id)\n",
    "    np.save(rpn_scores_raw_file, rpn_scores_raw)\n",
    "\n",
    "\n",
    "def eval_one_epoch_rpn(model, dataloader, epoch_id, result_dir, logger):\n",
    "    np.random.seed(1024)\n",
    "    mode = 'TEST' if args.test else 'EVAL'\n",
    "\n",
    "    if args.save_rpn_feature:\n",
    "        kitti_features_dir = os.path.join(result_dir, 'features')\n",
    "        os.makedirs(kitti_features_dir, exist_ok=True)\n",
    "\n",
    "    if args.save_result or args.save_rpn_feature:\n",
    "        kitti_output_dir = os.path.join(result_dir, 'detections', 'data')\n",
    "        seg_output_dir = os.path.join(result_dir, 'seg_result')\n",
    "        os.makedirs(kitti_output_dir, exist_ok=True)\n",
    "        os.makedirs(seg_output_dir, exist_ok=True)\n",
    "\n",
    "    logger.info('---- EPOCH %s RPN EVALUATION ----' % epoch_id)\n",
    "    model.eval()\n",
    "\n",
    "    thresh_list = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "    total_recalled_bbox_list, total_gt_bbox = [0] * 5, 0\n",
    "    dataset = dataloader.dataset\n",
    "    cnt = max_num = rpn_iou_avg = 0\n",
    "\n",
    "    progress_bar = tqdm.tqdm(total=len(dataloader), leave=True, desc='eval')\n",
    "\n",
    "    for data in dataloader:\n",
    "        sample_id_list, pts_rect, pts_features, pts_input = \\\n",
    "            data['sample_id'], data['pts_rect'], data['pts_features'], data['pts_input']\n",
    "        sample_id = sample_id_list[0]\n",
    "        cnt += len(sample_id_list)\n",
    "\n",
    "        if not args.test:\n",
    "            rpn_cls_label, rpn_reg_label = data['rpn_cls_label'], data['rpn_reg_label']\n",
    "            gt_boxes3d = data['gt_boxes3d']\n",
    "\n",
    "            rpn_cls_label = torch.from_numpy(rpn_cls_label).cuda(non_blocking=True).long()\n",
    "            if gt_boxes3d.shape[1] == 0:  # (B, M, 7)\n",
    "                pass\n",
    "                # logger.info('%06d: No gt box' % sample_id)\n",
    "            else:\n",
    "                gt_boxes3d = torch.from_numpy(gt_boxes3d).cuda(non_blocking=True).float()\n",
    "\n",
    "        inputs = torch.from_numpy(pts_input).cuda(non_blocking=True).float()\n",
    "        input_data = {'pts_input': inputs}\n",
    "\n",
    "        # model inference\n",
    "        ret_dict = model(input_data)\n",
    "        rpn_cls, rpn_reg = ret_dict['rpn_cls'], ret_dict['rpn_reg']\n",
    "        backbone_xyz, backbone_features = ret_dict['backbone_xyz'], ret_dict['backbone_features']\n",
    "\n",
    "        rpn_scores_raw = rpn_cls[:, :, 0]\n",
    "        rpn_scores = torch.sigmoid(rpn_scores_raw)\n",
    "        seg_result = (rpn_scores > cfg.RPN.SCORE_THRESH).long()\n",
    "\n",
    "        # proposal layer\n",
    "        rois, roi_scores_raw = model.rpn.proposal_layer(rpn_scores_raw, rpn_reg, backbone_xyz)  # (B, M, 7)\n",
    "        batch_size = rois.shape[0]\n",
    "\n",
    "        # calculate recall and save results to file\n",
    "        for bs_idx in range(batch_size):\n",
    "            cur_sample_id = sample_id_list[bs_idx]\n",
    "            cur_scores_raw = roi_scores_raw[bs_idx]  # (N)\n",
    "            cur_boxes3d = rois[bs_idx]  # (N, 7)\n",
    "            cur_seg_result = seg_result[bs_idx]\n",
    "            cur_pts_rect = pts_rect[bs_idx]\n",
    "\n",
    "            # calculate recall\n",
    "            if not args.test:\n",
    "                cur_rpn_cls_label = rpn_cls_label[bs_idx]\n",
    "                cur_gt_boxes3d = gt_boxes3d[bs_idx]\n",
    "\n",
    "                k = cur_gt_boxes3d.__len__() - 1\n",
    "                while k > 0 and cur_gt_boxes3d[k].sum() == 0:\n",
    "                    k -= 1\n",
    "                cur_gt_boxes3d = cur_gt_boxes3d[:k + 1]\n",
    "\n",
    "                recalled_num = 0\n",
    "                if cur_gt_boxes3d.shape[0] > 0:\n",
    "                    iou3d = iou3d_utils.boxes_iou3d_gpu(cur_boxes3d, cur_gt_boxes3d[:, 0:7])\n",
    "                    gt_max_iou, _ = iou3d.max(dim=0)\n",
    "\n",
    "                    for idx, thresh in enumerate(thresh_list):\n",
    "                        total_recalled_bbox_list[idx] += (gt_max_iou > thresh).sum().item()\n",
    "                    recalled_num = (gt_max_iou > 0.7).sum().item()\n",
    "                    total_gt_bbox += cur_gt_boxes3d.__len__()\n",
    "\n",
    "                fg_mask = cur_rpn_cls_label > 0\n",
    "                correct = ((cur_seg_result == cur_rpn_cls_label) & fg_mask).sum().float()\n",
    "                union = fg_mask.sum().float() + (cur_seg_result > 0).sum().float() - correct\n",
    "                rpn_iou = correct / torch.clamp(union, min=1.0)\n",
    "                rpn_iou_avg += rpn_iou.item()\n",
    "\n",
    "            # save result\n",
    "            if args.save_rpn_feature:\n",
    "                # save features to file\n",
    "                save_rpn_features(seg_result[bs_idx].float().cpu().numpy(),\n",
    "                                  rpn_scores_raw[bs_idx].float().cpu().numpy(),\n",
    "                                  pts_features[bs_idx],\n",
    "                                  backbone_xyz[bs_idx].cpu().numpy(),\n",
    "                                  backbone_features[bs_idx].cpu().numpy().transpose(1, 0),\n",
    "                                  kitti_features_dir, cur_sample_id)\n",
    "\n",
    "            if args.save_result or args.save_rpn_feature:\n",
    "                cur_pred_cls = cur_seg_result.cpu().numpy()\n",
    "                output_file = os.path.join(seg_output_dir, '%06d.npy' % cur_sample_id)\n",
    "                if not args.test:\n",
    "                    cur_gt_cls = cur_rpn_cls_label.cpu().numpy()\n",
    "                    output_data = np.concatenate(\n",
    "                        (cur_pts_rect.reshape(-1, 3), cur_gt_cls.reshape(-1, 1), cur_pred_cls.reshape(-1, 1)), axis=1)\n",
    "                else:\n",
    "                    output_data = np.concatenate((cur_pts_rect.reshape(-1, 3), cur_pred_cls.reshape(-1, 1)), axis=1)\n",
    "\n",
    "                np.save(output_file, output_data.astype(np.float16))\n",
    "\n",
    "                # save as kitti format\n",
    "                calib = dataset.get_calib(cur_sample_id)\n",
    "                cur_boxes3d = cur_boxes3d.cpu().numpy()\n",
    "                image_shape = dataset.get_image_shape(cur_sample_id)\n",
    "                save_kitti_format(cur_sample_id, calib, cur_boxes3d, kitti_output_dir, cur_scores_raw, image_shape)\n",
    "\n",
    "        disp_dict = {'mode': mode, 'recall': '%d/%d' % (total_recalled_bbox_list[3], total_gt_bbox),\n",
    "                     'rpn_iou': rpn_iou_avg / max(cnt, 1.0)}\n",
    "        progress_bar.set_postfix(disp_dict)\n",
    "        progress_bar.update()\n",
    "\n",
    "    progress_bar.close()\n",
    "\n",
    "    logger.info(str(datetime.now()))\n",
    "    logger.info('-------------------performance of epoch %s---------------------' % epoch_id)\n",
    "    logger.info('max number of objects: %d' % max_num)\n",
    "    logger.info('rpn iou avg: %f' % (rpn_iou_avg / max(cnt, 1.0)))\n",
    "\n",
    "    ret_dict = {'max_obj_num': max_num, 'rpn_iou': rpn_iou_avg / cnt}\n",
    "\n",
    "    for idx, thresh in enumerate(thresh_list):\n",
    "        cur_recall = total_recalled_bbox_list[idx] / max(total_gt_bbox, 1.0)\n",
    "        logger.info('total bbox recall(thresh=%.3f): %d / %d = %f' % (thresh, total_recalled_bbox_list[idx],\n",
    "                    total_gt_bbox, cur_recall))\n",
    "        ret_dict['rpn_recall(thresh=%.2f)' % thresh] = cur_recall\n",
    "    logger.info('result is saved to: %s' % result_dir)\n",
    "\n",
    "    return ret_dict\n",
    "\n",
    "\n",
    "def eval_one_epoch_rcnn(model, dataloader, epoch_id, result_dir, logger):\n",
    "    np.random.seed(1024)\n",
    "    MEAN_SIZE = torch.from_numpy(cfg.CLS_MEAN_SIZE[0]).cuda()\n",
    "    mode = 'TEST' if args.test else 'EVAL'\n",
    "\n",
    "    final_output_dir = os.path.join(result_dir, 'final_result', 'data')\n",
    "    os.makedirs(final_output_dir, exist_ok=True)\n",
    "\n",
    "    if args.save_result:\n",
    "        roi_output_dir = os.path.join(result_dir, 'roi_result', 'data')\n",
    "        refine_output_dir = os.path.join(result_dir, 'refine_result', 'data')\n",
    "        os.makedirs(roi_output_dir, exist_ok=True)\n",
    "        os.makedirs(refine_output_dir, exist_ok=True)\n",
    "\n",
    "    logger.info('---- EPOCH %s RCNN EVALUATION ----' % epoch_id)\n",
    "    model.eval()\n",
    "\n",
    "    thresh_list = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "    total_recalled_bbox_list, total_gt_bbox = [0] * 5, 0\n",
    "    total_roi_recalled_bbox_list = [0] * 5\n",
    "    dataset = dataloader.dataset\n",
    "    cnt = final_total = total_cls_acc = total_cls_acc_refined = 0\n",
    "\n",
    "    progress_bar = tqdm.tqdm(total=len(dataloader), leave=True, desc='eval')\n",
    "    for data in dataloader:\n",
    "        sample_id = data['sample_id']\n",
    "        cnt += 1\n",
    "        assert args.batch_size == 1, 'Only support bs=1 here'\n",
    "        input_data = {}\n",
    "        for key, val in data.items():\n",
    "            if key != 'sample_id':\n",
    "                input_data[key] = torch.from_numpy(val).contiguous().cuda(non_blocking=True).float()\n",
    "\n",
    "        roi_boxes3d = input_data['roi_boxes3d']\n",
    "        roi_scores = input_data['roi_scores']\n",
    "        if cfg.RCNN.ROI_SAMPLE_JIT:\n",
    "            for key, val in input_data.items():\n",
    "                if key in ['gt_iou', 'gt_boxes3d']:\n",
    "                    continue\n",
    "                input_data[key] = input_data[key].unsqueeze(dim=0)\n",
    "        else:\n",
    "            pts_input = torch.cat((input_data['pts_input'], input_data['pts_features']), dim=-1)\n",
    "            input_data['pts_input'] = pts_input\n",
    "\n",
    "        ret_dict = model(input_data)\n",
    "        rcnn_cls = ret_dict['rcnn_cls']\n",
    "        rcnn_reg = ret_dict['rcnn_reg']\n",
    "\n",
    "        # bounding box regression\n",
    "        anchor_size = MEAN_SIZE\n",
    "        if cfg.RCNN.SIZE_RES_ON_ROI:\n",
    "            roi_size = input_data['roi_size']\n",
    "            anchor_size = roi_size\n",
    "\n",
    "        pred_boxes3d = decode_bbox_target(roi_boxes3d, rcnn_reg,\n",
    "                                          anchor_size=anchor_size,\n",
    "                                          loc_scope=cfg.RCNN.LOC_SCOPE,\n",
    "                                          loc_bin_size=cfg.RCNN.LOC_BIN_SIZE,\n",
    "                                          num_head_bin=cfg.RCNN.NUM_HEAD_BIN,\n",
    "                                          get_xz_fine=True, get_y_by_bin=cfg.RCNN.LOC_Y_BY_BIN,\n",
    "                                          loc_y_scope=cfg.RCNN.LOC_Y_SCOPE, loc_y_bin_size=cfg.RCNN.LOC_Y_BIN_SIZE,\n",
    "                                          get_ry_fine=True)\n",
    "\n",
    "        # scoring\n",
    "        if rcnn_cls.shape[1] == 1:\n",
    "            raw_scores = rcnn_cls.view(-1)\n",
    "            norm_scores = torch.sigmoid(raw_scores)\n",
    "            pred_classes = (norm_scores > cfg.RCNN.SCORE_THRESH).long()\n",
    "        else:\n",
    "            pred_classes = torch.argmax(rcnn_cls, dim=1).view(-1)\n",
    "            cls_norm_scores = F.softmax(rcnn_cls, dim=1)\n",
    "            raw_scores = rcnn_cls[:, pred_classes]\n",
    "            norm_scores = cls_norm_scores[:, pred_classes]\n",
    "\n",
    "        # evaluation\n",
    "        disp_dict = {'mode': mode}\n",
    "        if not args.test:\n",
    "            gt_boxes3d = input_data['gt_boxes3d']\n",
    "            gt_iou = input_data['gt_iou']\n",
    "\n",
    "            # calculate recall\n",
    "            gt_num = gt_boxes3d.shape[0]\n",
    "            if gt_num > 0:\n",
    "                iou3d = iou3d_utils.boxes_iou3d_gpu(pred_boxes3d, gt_boxes3d)\n",
    "                gt_max_iou, _ = iou3d.max(dim=0)\n",
    "                refined_iou, _ = iou3d.max(dim=1)\n",
    "\n",
    "                for idx, thresh in enumerate(thresh_list):\n",
    "                    total_recalled_bbox_list[idx] += (gt_max_iou > thresh).sum().item()\n",
    "                recalled_num = (gt_max_iou > 0.7).sum().item()\n",
    "                total_gt_bbox += gt_num\n",
    "\n",
    "                iou3d_in = iou3d_utils.boxes_iou3d_gpu(roi_boxes3d, gt_boxes3d)\n",
    "                gt_max_iou_in, _ = iou3d_in.max(dim=0)\n",
    "\n",
    "                for idx, thresh in enumerate(thresh_list):\n",
    "                    total_roi_recalled_bbox_list[idx] += (gt_max_iou_in > thresh).sum().item()\n",
    "\n",
    "            # classification accuracy\n",
    "            cls_label = (gt_iou > cfg.RCNN.CLS_FG_THRESH).float()\n",
    "            cls_valid_mask = ((gt_iou >= cfg.RCNN.CLS_FG_THRESH) | (gt_iou <= cfg.RCNN.CLS_BG_THRESH)).float()\n",
    "            cls_acc = ((pred_classes == cls_label.long()).float() * cls_valid_mask).sum() / max(cls_valid_mask.sum(), 1.0)\n",
    "\n",
    "            iou_thresh = 0.7 if cfg.CLASSES == 'Car' else 0.5\n",
    "            cls_label_refined = (gt_iou >= iou_thresh).float()\n",
    "            cls_acc_refined = (pred_classes == cls_label_refined.long()).float().sum() / max(cls_label_refined.shape[0], 1.0)\n",
    "\n",
    "            total_cls_acc += cls_acc.item()\n",
    "            total_cls_acc_refined += cls_acc_refined.item()\n",
    "\n",
    "            disp_dict['recall'] = '%d/%d' % (total_recalled_bbox_list[3], total_gt_bbox)\n",
    "            disp_dict['cls_acc_refined'] = '%.2f' % cls_acc_refined.item()\n",
    "\n",
    "        progress_bar.set_postfix(disp_dict)\n",
    "        progress_bar.update()\n",
    "\n",
    "        image_shape = dataset.get_image_shape(sample_id)\n",
    "        if args.save_result:\n",
    "            # save roi and refine results\n",
    "            roi_boxes3d_np = roi_boxes3d.cpu().numpy()\n",
    "            pred_boxes3d_np = pred_boxes3d.cpu().numpy()\n",
    "            calib = dataset.get_calib(sample_id)\n",
    "\n",
    "            save_kitti_format(sample_id, calib, roi_boxes3d_np, roi_output_dir, roi_scores, image_shape)\n",
    "            save_kitti_format(sample_id, calib, pred_boxes3d_np, refine_output_dir, raw_scores.cpu().numpy(),\n",
    "                              image_shape)\n",
    "\n",
    "        # NMS and scoring\n",
    "        # scores thresh\n",
    "        inds = norm_scores > cfg.RCNN.SCORE_THRESH\n",
    "        if inds.sum() == 0:\n",
    "            continue\n",
    "\n",
    "        pred_boxes3d_selected = pred_boxes3d[inds]\n",
    "        raw_scores_selected = raw_scores[inds]\n",
    "\n",
    "        # NMS thresh\n",
    "        boxes_bev_selected = kitti_utils.boxes3d_to_bev_torch(pred_boxes3d_selected)\n",
    "        keep_idx = iou3d_utils.nms_gpu(boxes_bev_selected, raw_scores_selected, cfg.RCNN.NMS_THRESH)\n",
    "        pred_boxes3d_selected = pred_boxes3d_selected[keep_idx]\n",
    "\n",
    "        scores_selected = raw_scores_selected[keep_idx]\n",
    "        pred_boxes3d_selected, scores_selected = pred_boxes3d_selected.cpu().numpy(), scores_selected.cpu().numpy()\n",
    "\n",
    "        calib = dataset.get_calib(sample_id)\n",
    "        final_total += pred_boxes3d_selected.shape[0]\n",
    "        save_kitti_format(sample_id, calib, pred_boxes3d_selected, final_output_dir, scores_selected, image_shape)\n",
    "\n",
    "    progress_bar.close()\n",
    "\n",
    "    # dump empty files\n",
    "    split_file = os.path.join(dataset.imageset_dir, '..', '..', 'ImageSets', dataset.split + '.txt')\n",
    "    split_file = os.path.abspath(split_file)\n",
    "    image_idx_list = [x.strip() for x in open(split_file).readlines()]\n",
    "    empty_cnt = 0\n",
    "    for k in range(image_idx_list.__len__()):\n",
    "        cur_file = os.path.join(final_output_dir, '%s.txt' % image_idx_list[k])\n",
    "        if not os.path.exists(cur_file):\n",
    "            with open(cur_file, 'w') as temp_f:\n",
    "                pass\n",
    "            empty_cnt += 1\n",
    "            logger.info('empty_cnt=%d: dump empty file %s' % (empty_cnt, cur_file))\n",
    "\n",
    "    ret_dict = {'empty_cnt': empty_cnt}\n",
    "\n",
    "    logger.info('-------------------performance of epoch %s---------------------' % epoch_id)\n",
    "    logger.info(str(datetime.now()))\n",
    "\n",
    "    avg_cls_acc = (total_cls_acc / max(cnt, 1.0))\n",
    "    avg_cls_acc_refined = (total_cls_acc_refined / max(cnt, 1.0))\n",
    "    avg_det_num = (final_total / max(cnt, 1.0))\n",
    "    logger.info('final average detections: %.3f' % avg_det_num)\n",
    "    logger.info('final average cls acc: %.3f' % avg_cls_acc)\n",
    "    logger.info('final average cls acc refined: %.3f' % avg_cls_acc_refined)\n",
    "    ret_dict['rcnn_cls_acc'] = avg_cls_acc\n",
    "    ret_dict['rcnn_cls_acc_refined'] = avg_cls_acc_refined\n",
    "    ret_dict['rcnn_avg_num'] = avg_det_num\n",
    "\n",
    "    for idx, thresh in enumerate(thresh_list):\n",
    "        cur_roi_recall = total_roi_recalled_bbox_list[idx] / max(total_gt_bbox, 1.0)\n",
    "        logger.info('total roi bbox recall(thresh=%.3f): %d / %d = %f' % (thresh, total_roi_recalled_bbox_list[idx],\n",
    "                                                                          total_gt_bbox, cur_roi_recall))\n",
    "        ret_dict['rpn_recall(thresh=%.2f)' % thresh] = cur_roi_recall\n",
    "\n",
    "    for idx, thresh in enumerate(thresh_list):\n",
    "        cur_recall = total_recalled_bbox_list[idx] / max(total_gt_bbox, 1.0)\n",
    "        logger.info('total bbox recall(thresh=%.3f): %d / %d = %f' % (thresh, total_recalled_bbox_list[idx],\n",
    "                                                                      total_gt_bbox, cur_recall))\n",
    "        ret_dict['rcnn_recall(thresh=%.2f)' % thresh] = cur_recall\n",
    "\n",
    "    if cfg.TEST.SPLIT != 'test':\n",
    "        logger.info('Averate Precision:')\n",
    "        name_to_class = {'Car': 0, 'Pedestrian': 1, 'Cyclist': 2}\n",
    "        ap_result_str, ap_dict = kitti_evaluate(dataset.label_dir, final_output_dir, label_split_file=split_file,\n",
    "                                                current_class=name_to_class[cfg.CLASSES])\n",
    "        logger.info(ap_result_str)\n",
    "        ret_dict.update(ap_dict)\n",
    "\n",
    "    logger.info('result is saved to: %s' % result_dir)\n",
    "\n",
    "    return ret_dict\n",
    "\n",
    "\n",
    "def eval_one_epoch_joint(model, dataloader, epoch_id, result_dir, logger):\n",
    "    np.random.seed(666)\n",
    "    MEAN_SIZE = torch.from_numpy(cfg.CLS_MEAN_SIZE[0]).cuda()\n",
    "    mode = 'TEST' if args.test else 'EVAL'\n",
    "\n",
    "    final_output_dir = os.path.join(result_dir, 'final_result', 'data')\n",
    "    os.makedirs(final_output_dir, exist_ok=True)\n",
    "\n",
    "    if args.save_result:\n",
    "        roi_output_dir = os.path.join(result_dir, 'roi_result', 'data')\n",
    "        refine_output_dir = os.path.join(result_dir, 'refine_result', 'data')\n",
    "        rpn_output_dir = os.path.join(result_dir, 'rpn_result', 'data')\n",
    "        os.makedirs(rpn_output_dir, exist_ok=True)\n",
    "        os.makedirs(roi_output_dir, exist_ok=True)\n",
    "        os.makedirs(refine_output_dir, exist_ok=True)\n",
    "\n",
    "    logger.info('---- EPOCH %s JOINT EVALUATION ----' % epoch_id)\n",
    "    logger.info('==> Output file: %s' % result_dir)\n",
    "    model.eval()\n",
    "\n",
    "    thresh_list = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "    total_recalled_bbox_list, total_gt_bbox = [0] * 5, 0\n",
    "    total_roi_recalled_bbox_list = [0] * 5\n",
    "    dataset = dataloader.dataset\n",
    "    cnt = final_total = total_cls_acc = total_cls_acc_refined = total_rpn_iou = 0\n",
    "\n",
    "    progress_bar = tqdm.tqdm(total=len(dataloader), leave=True, desc='eval')\n",
    "    for data in dataloader:\n",
    "        cnt += 1\n",
    "        sample_id, pts_rect, pts_features, pts_input = \\\n",
    "            data['sample_id'], data['pts_rect'], data['pts_features'], data['pts_input']\n",
    "        batch_size = len(sample_id)\n",
    "        inputs = torch.from_numpy(pts_input).cuda(non_blocking=True).float()\n",
    "        input_data = {'pts_input': inputs}\n",
    "\n",
    "        # model inference\n",
    "        ret_dict = model(input_data)\n",
    "\n",
    "        roi_scores_raw = ret_dict['roi_scores_raw']  # (B, M)\n",
    "        roi_boxes3d = ret_dict['rois']  # (B, M, 7)\n",
    "        seg_result = ret_dict['seg_result'].long()  # (B, N)\n",
    "\n",
    "        rcnn_cls = ret_dict['rcnn_cls'].view(batch_size, -1, ret_dict['rcnn_cls'].shape[1])\n",
    "        rcnn_reg = ret_dict['rcnn_reg'].view(batch_size, -1, ret_dict['rcnn_reg'].shape[1])  # (B, M, C)\n",
    "\n",
    "        # bounding box regression\n",
    "        anchor_size = MEAN_SIZE\n",
    "        if cfg.RCNN.SIZE_RES_ON_ROI:\n",
    "            assert False\n",
    "\n",
    "        pred_boxes3d = decode_bbox_target(roi_boxes3d.view(-1, 7), rcnn_reg.view(-1, rcnn_reg.shape[-1]),\n",
    "                                          anchor_size=anchor_size,\n",
    "                                          loc_scope=cfg.RCNN.LOC_SCOPE,\n",
    "                                          loc_bin_size=cfg.RCNN.LOC_BIN_SIZE,\n",
    "                                          num_head_bin=cfg.RCNN.NUM_HEAD_BIN,\n",
    "                                          get_xz_fine=True, get_y_by_bin=cfg.RCNN.LOC_Y_BY_BIN,\n",
    "                                          loc_y_scope=cfg.RCNN.LOC_Y_SCOPE, loc_y_bin_size=cfg.RCNN.LOC_Y_BIN_SIZE,\n",
    "                                          get_ry_fine=True).view(batch_size, -1, 7)\n",
    "\n",
    "        # scoring\n",
    "        if rcnn_cls.shape[2] == 1:\n",
    "            raw_scores = rcnn_cls  # (B, M, 1)\n",
    "\n",
    "            norm_scores = torch.sigmoid(raw_scores)\n",
    "            pred_classes = (norm_scores > cfg.RCNN.SCORE_THRESH).long()\n",
    "        else:\n",
    "            pred_classes = torch.argmax(rcnn_cls, dim=1).view(-1)\n",
    "            cls_norm_scores = F.softmax(rcnn_cls, dim=1)\n",
    "            raw_scores = rcnn_cls[:, pred_classes]\n",
    "            norm_scores = cls_norm_scores[:, pred_classes]\n",
    "\n",
    "        # evaluation\n",
    "        recalled_num = gt_num = rpn_iou = 0\n",
    "        if not args.test:\n",
    "            if not cfg.RPN.FIXED:\n",
    "                rpn_cls_label, rpn_reg_label = data['rpn_cls_label'], data['rpn_reg_label']\n",
    "                rpn_cls_label = torch.from_numpy(rpn_cls_label).cuda(non_blocking=True).long()\n",
    "\n",
    "            gt_boxes3d = data['gt_boxes3d']\n",
    "\n",
    "            for k in range(batch_size):\n",
    "                # calculate recall\n",
    "                cur_gt_boxes3d = gt_boxes3d[k]\n",
    "                tmp_idx = cur_gt_boxes3d.__len__() - 1\n",
    "\n",
    "                while tmp_idx >= 0 and cur_gt_boxes3d[tmp_idx].sum() == 0:\n",
    "                    tmp_idx -= 1\n",
    "\n",
    "                if tmp_idx >= 0:\n",
    "                    cur_gt_boxes3d = cur_gt_boxes3d[:tmp_idx + 1]\n",
    "\n",
    "                    cur_gt_boxes3d = torch.from_numpy(cur_gt_boxes3d).cuda(non_blocking=True).float()\n",
    "                    iou3d = iou3d_utils.boxes_iou3d_gpu(pred_boxes3d[k], cur_gt_boxes3d)\n",
    "                    gt_max_iou, _ = iou3d.max(dim=0)\n",
    "                    refined_iou, _ = iou3d.max(dim=1)\n",
    "\n",
    "                    for idx, thresh in enumerate(thresh_list):\n",
    "                        total_recalled_bbox_list[idx] += (gt_max_iou > thresh).sum().item()\n",
    "                    recalled_num += (gt_max_iou > 0.7).sum().item()\n",
    "                    gt_num += cur_gt_boxes3d.shape[0]\n",
    "                    total_gt_bbox += cur_gt_boxes3d.shape[0]\n",
    "\n",
    "                    # original recall\n",
    "                    iou3d_in = iou3d_utils.boxes_iou3d_gpu(roi_boxes3d[k], cur_gt_boxes3d)\n",
    "                    gt_max_iou_in, _ = iou3d_in.max(dim=0)\n",
    "\n",
    "                    for idx, thresh in enumerate(thresh_list):\n",
    "                        total_roi_recalled_bbox_list[idx] += (gt_max_iou_in > thresh).sum().item()\n",
    "\n",
    "                if not cfg.RPN.FIXED:\n",
    "                    fg_mask = rpn_cls_label > 0\n",
    "                    correct = ((seg_result == rpn_cls_label) & fg_mask).sum().float()\n",
    "                    union = fg_mask.sum().float() + (seg_result > 0).sum().float() - correct\n",
    "                    rpn_iou = correct / torch.clamp(union, min=1.0)\n",
    "                    total_rpn_iou += rpn_iou.item()\n",
    "\n",
    "        disp_dict = {'mode': mode, 'recall': '%d/%d' % (total_recalled_bbox_list[3], total_gt_bbox)}\n",
    "        progress_bar.set_postfix(disp_dict)\n",
    "        progress_bar.update()\n",
    "\n",
    "        if args.save_result:\n",
    "            # save roi and refine results\n",
    "            roi_boxes3d_np = roi_boxes3d.cpu().numpy()\n",
    "            pred_boxes3d_np = pred_boxes3d.cpu().numpy()\n",
    "            roi_scores_raw_np = roi_scores_raw.cpu().numpy()\n",
    "            raw_scores_np = raw_scores.cpu().numpy()\n",
    "\n",
    "            rpn_cls_np = ret_dict['rpn_cls'].cpu().numpy()\n",
    "            rpn_xyz_np = ret_dict['backbone_xyz'].cpu().numpy()\n",
    "            seg_result_np = seg_result.cpu().numpy()\n",
    "            output_data = np.concatenate((rpn_xyz_np, rpn_cls_np.reshape(batch_size, -1, 1),\n",
    "                                          seg_result_np.reshape(batch_size, -1, 1)), axis=2)\n",
    "\n",
    "            for k in range(batch_size):\n",
    "                cur_sample_id = sample_id[k]\n",
    "                calib = dataset.get_calib(cur_sample_id)\n",
    "                image_shape = dataset.get_image_shape(cur_sample_id)\n",
    "                save_kitti_format(cur_sample_id, calib, roi_boxes3d_np[k], roi_output_dir,\n",
    "                                  roi_scores_raw_np[k], image_shape)\n",
    "                save_kitti_format(cur_sample_id, calib, pred_boxes3d_np[k], refine_output_dir,\n",
    "                                  raw_scores_np[k], image_shape)\n",
    "\n",
    "                output_file = os.path.join(rpn_output_dir, '%06d.npy' % cur_sample_id)\n",
    "                np.save(output_file, output_data.astype(np.float32))\n",
    "\n",
    "        # scores thresh\n",
    "        inds = norm_scores > cfg.RCNN.SCORE_THRESH\n",
    "\n",
    "        for k in range(batch_size):\n",
    "            cur_inds = inds[k].view(-1)\n",
    "            if cur_inds.sum() == 0:\n",
    "                continue\n",
    "\n",
    "            pred_boxes3d_selected = pred_boxes3d[k, cur_inds]\n",
    "            raw_scores_selected = raw_scores[k, cur_inds]\n",
    "            norm_scores_selected = norm_scores[k, cur_inds]\n",
    "\n",
    "            # NMS thresh\n",
    "            # rotated nms\n",
    "            boxes_bev_selected = kitti_utils.boxes3d_to_bev_torch(pred_boxes3d_selected)\n",
    "            keep_idx = iou3d_utils.nms_gpu(boxes_bev_selected, raw_scores_selected, cfg.RCNN.NMS_THRESH).view(-1)\n",
    "            pred_boxes3d_selected = pred_boxes3d_selected[keep_idx]\n",
    "            scores_selected = raw_scores_selected[keep_idx]\n",
    "            pred_boxes3d_selected, scores_selected = pred_boxes3d_selected.cpu().numpy(), scores_selected.cpu().numpy()\n",
    "\n",
    "            cur_sample_id = sample_id[k]\n",
    "            calib = dataset.get_calib(cur_sample_id)\n",
    "            final_total += pred_boxes3d_selected.shape[0]\n",
    "            image_shape = dataset.get_image_shape(cur_sample_id)\n",
    "            save_kitti_format(cur_sample_id, calib, pred_boxes3d_selected, final_output_dir, scores_selected, image_shape)\n",
    "\n",
    "    progress_bar.close()\n",
    "    # dump empty files\n",
    "    split_file = os.path.join(dataset.imageset_dir, '..', 'ImageSets', dataset.split + '.txt')\n",
    "    print('split_file---', split_file)\n",
    "    split_file = os.path.abspath(split_file)\n",
    "    print('split_file---', split_file)\n",
    "    image_idx_list = [x.strip() for x in open(split_file).readlines()]\n",
    "    print('image_idx_list---', image_idx_list)\n",
    "    empty_cnt = 0\n",
    "    for k in range(image_idx_list.__len__()):\n",
    "        cur_file = os.path.join(final_output_dir, '%s.txt' % image_idx_list[k])\n",
    "        if not os.path.exists(cur_file):\n",
    "            with open(cur_file, 'w') as temp_f:\n",
    "                pass\n",
    "            empty_cnt += 1\n",
    "            logger.info('empty_cnt=%d: dump empty file %s' % (empty_cnt, cur_file))\n",
    "\n",
    "    ret_dict = {'empty_cnt': empty_cnt}\n",
    "\n",
    "    logger.info('-------------------performance of epoch %s---------------------' % epoch_id)\n",
    "    logger.info(str(datetime.now()))\n",
    "\n",
    "    avg_rpn_iou = (total_rpn_iou / max(cnt, 1.0))\n",
    "    avg_cls_acc = (total_cls_acc / max(cnt, 1.0))\n",
    "    avg_cls_acc_refined = (total_cls_acc_refined / max(cnt, 1.0))\n",
    "    avg_det_num = (final_total / max(len(dataset), 1.0))\n",
    "    logger.info('final average detections: %.3f' % avg_det_num)\n",
    "    logger.info('final average rpn_iou refined: %.3f' % avg_rpn_iou)\n",
    "    logger.info('final average cls acc: %.3f' % avg_cls_acc)\n",
    "    logger.info('final average cls acc refined: %.3f' % avg_cls_acc_refined)\n",
    "    ret_dict['rpn_iou'] = avg_rpn_iou\n",
    "    ret_dict['rcnn_cls_acc'] = avg_cls_acc\n",
    "    ret_dict['rcnn_cls_acc_refined'] = avg_cls_acc_refined\n",
    "    ret_dict['rcnn_avg_num'] = avg_det_num\n",
    "\n",
    "    for idx, thresh in enumerate(thresh_list):\n",
    "        cur_roi_recall = total_roi_recalled_bbox_list[idx] / max(total_gt_bbox, 1.0)\n",
    "        logger.info('total roi bbox recall(thresh=%.3f): %d / %d = %f' % (thresh, total_roi_recalled_bbox_list[idx],\n",
    "                                                                          total_gt_bbox, cur_roi_recall))\n",
    "        ret_dict['rpn_recall(thresh=%.2f)' % thresh] = cur_roi_recall\n",
    "\n",
    "    for idx, thresh in enumerate(thresh_list):\n",
    "        cur_recall = total_recalled_bbox_list[idx] / max(total_gt_bbox, 1.0)\n",
    "        logger.info('total bbox recall(thresh=%.3f): %d / %d = %f' % (thresh, total_recalled_bbox_list[idx],\n",
    "                                                                      total_gt_bbox, cur_recall))\n",
    "        ret_dict['rcnn_recall(thresh=%.2f)' % thresh] = cur_recall\n",
    "\n",
    "    if cfg.TEST.SPLIT != 'test':\n",
    "        logger.info('Averate Precision:')\n",
    "        name_to_class = {'Car': 0, 'Pedestrian': 1, 'Cyclist': 2}\n",
    "        print(dataset.label_dir, final_output_dir, split_file,name_to_class[cfg.CLASSES])\n",
    "        ap_result_str, ap_dict = kitti_evaluate(dataset.label_dir, final_output_dir, label_split_file=split_file,\n",
    "                                                current_class=name_to_class[cfg.CLASSES])\n",
    "        logger.info(ap_result_str)\n",
    "        ret_dict.update(ap_dict)\n",
    "\n",
    "    logger.info('result is saved to: %s' % result_dir)\n",
    "    return ret_dict\n",
    "\n",
    "\n",
    "def eval_one_epoch(model, dataloader, epoch_id, result_dir, logger):\n",
    "    if cfg.RPN.ENABLED and not cfg.RCNN.ENABLED:\n",
    "        ret_dict = eval_one_epoch_rpn(model, dataloader, epoch_id, result_dir, logger)\n",
    "    elif not cfg.RPN.ENABLED and cfg.RCNN.ENABLED:\n",
    "        ret_dict = eval_one_epoch_rcnn(model, dataloader, epoch_id, result_dir, logger)\n",
    "    elif cfg.RPN.ENABLED and cfg.RCNN.ENABLED:\n",
    "        ret_dict = eval_one_epoch_joint(model, dataloader, epoch_id, result_dir, logger)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return ret_dict\n",
    "\n",
    "\n",
    "def load_part_ckpt(model, filename, logger, total_keys=-1):\n",
    "    if os.path.isfile(filename):\n",
    "        logger.info(\"==> Loading part model from checkpoint '{}'\".format(filename))\n",
    "        checkpoint = torch.load(filename)\n",
    "        model_state = checkpoint['model_state']\n",
    "\n",
    "        update_model_state = {key: val for key, val in model_state.items() if key in model.state_dict()}\n",
    "        state_dict = model.state_dict()\n",
    "        state_dict.update(update_model_state)\n",
    "        model.load_state_dict(state_dict)\n",
    "\n",
    "        update_keys = update_model_state.keys().__len__()\n",
    "        if update_keys == 0:\n",
    "            raise RuntimeError\n",
    "        logger.info(\"==> Done (loaded %d/%d)\" % (update_keys, total_keys))\n",
    "    else:\n",
    "        raise FileNotFoundError\n",
    "\n",
    "\n",
    "def load_ckpt_based_on_args(model, logger):\n",
    "    if args.ckpt is not None:\n",
    "        train_utils.load_checkpoint(model, filename=args.ckpt, logger=logger)\n",
    "\n",
    "    total_keys = model.state_dict().keys().__len__()\n",
    "    if cfg.RPN.ENABLED and args.rpn_ckpt is not None:\n",
    "        load_part_ckpt(model, filename=args.rpn_ckpt, logger=logger, total_keys=total_keys)\n",
    "\n",
    "    if cfg.RCNN.ENABLED and args.rcnn_ckpt is not None:\n",
    "        load_part_ckpt(model, filename=args.rcnn_ckpt, logger=logger, total_keys=total_keys)\n",
    "\n",
    "\n",
    "def eval_single_ckpt(root_result_dir):\n",
    "    root_result_dir = os.path.join(root_result_dir, 'eval')\n",
    "    # set epoch_id and output dir\n",
    "    num_list = re.findall(r'\\d+', args.ckpt) if args.ckpt is not None else []\n",
    "    epoch_id = num_list[-1] if num_list.__len__() > 0 else 'no_number'\n",
    "    root_result_dir = os.path.join(root_result_dir, 'epoch_%s' % epoch_id, cfg.TEST.SPLIT)\n",
    "    if args.test:\n",
    "        root_result_dir = os.path.join(root_result_dir, 'test_mode')\n",
    "\n",
    "    if args.extra_tag != 'default':\n",
    "        root_result_dir = os.path.join(root_result_dir, args.extra_tag)\n",
    "    os.makedirs(root_result_dir, exist_ok=True)\n",
    "\n",
    "    log_file = os.path.join(root_result_dir, 'log_eval_one.txt')\n",
    "    logger = create_logger(log_file)\n",
    "    logger.info('**********************Start logging**********************')\n",
    "    for key, val in vars(args).items():\n",
    "        logger.info(\"{:16} {}\".format(key, val))\n",
    "    save_config_to_file(cfg, logger=logger)\n",
    "\n",
    "    # create dataloader & network\n",
    "    test_loader = create_dataloader(logger)\n",
    "    model = PointRCNN(num_classes=test_loader.dataset.num_class, use_xyz=True, mode='TEST')\n",
    "    model.cuda()\n",
    "\n",
    "    # copy important files to backup\n",
    "    backup_dir = os.path.join(root_result_dir, 'backup_files')\n",
    "    os.makedirs(backup_dir, exist_ok=True)\n",
    "    os.system('cp *.py %s/' % backup_dir)\n",
    "    os.system('cp ../lib/net/*.py %s/' % backup_dir)\n",
    "    os.system('cp ../lib/datasets/kitti_rcnn_dataset.py %s/' % backup_dir)\n",
    "\n",
    "    # load checkpoint\n",
    "    load_ckpt_based_on_args(model, logger)\n",
    "\n",
    "    # start evaluation\n",
    "    eval_one_epoch(model, test_loader, epoch_id, root_result_dir, logger)\n",
    "\n",
    "\n",
    "def get_no_evaluated_ckpt(ckpt_dir, ckpt_record_file):\n",
    "    ckpt_list = glob.glob(os.path.join(ckpt_dir, '*checkpoint_epoch_*.pth'))\n",
    "    ckpt_list.sort(key=os.path.getmtime)\n",
    "    evaluated_ckpt_list = [float(x.strip()) for x in open(ckpt_record_file, 'r').readlines()]\n",
    "\n",
    "    for cur_ckpt in ckpt_list:\n",
    "        num_list = re.findall('checkpoint_epoch_(.*).pth', cur_ckpt)\n",
    "        if num_list.__len__() == 0:\n",
    "            continue\n",
    "\n",
    "        epoch_id = num_list[-1]\n",
    "        if float(epoch_id) not in evaluated_ckpt_list and int(float(epoch_id)) >= args.start_epoch:\n",
    "            return epoch_id, cur_ckpt\n",
    "    return -1, None\n",
    "\n",
    "\n",
    "def repeat_eval_ckpt(root_result_dir, ckpt_dir):\n",
    "    root_result_dir = os.path.join(root_result_dir, 'eval', 'eval_all_' + args.extra_tag)\n",
    "    os.makedirs(root_result_dir, exist_ok=True)\n",
    "\n",
    "    log_file = os.path.join(root_result_dir, 'log_eval_all_%s.txt' % cfg.TEST.SPLIT)\n",
    "    logger = create_logger(log_file)\n",
    "    logger.info('**********************Start logging**********************')\n",
    "\n",
    "    # save config\n",
    "    for key, val in vars(args).items():\n",
    "        logger.info(\"{:16} {}\".format(key, val))\n",
    "    save_config_to_file(cfg, logger=logger)\n",
    "\n",
    "    # create dataloader & network\n",
    "    test_loader = create_dataloader(logger)\n",
    "    model = PointRCNN(num_classes=test_loader.dataset.num_class, use_xyz=True, mode='TEST')\n",
    "    model.cuda()\n",
    "\n",
    "    # copy important files to backup\n",
    "    backup_dir = os.path.join(root_result_dir, 'backup_files')\n",
    "    os.makedirs(backup_dir, exist_ok=True)\n",
    "    os.system('cp *.py %s/' % backup_dir)\n",
    "    os.system('cp ../lib/net/*.py %s/' % backup_dir)\n",
    "    os.system('cp ../lib/datasets/kitti_rcnn_dataset.py %s/' % backup_dir)\n",
    "\n",
    "    # evaluated ckpt record\n",
    "    ckpt_record_file = os.path.join(root_result_dir, 'eval_list_%s.txt' % cfg.TEST.SPLIT)\n",
    "    with open(ckpt_record_file, 'a'):\n",
    "        pass\n",
    "\n",
    "    # tensorboard log\n",
    "    tb_log = SummaryWriter(log_dir=os.path.join(root_result_dir, 'tensorboard_%s' % cfg.TEST.SPLIT))\n",
    "\n",
    "    while True:\n",
    "        # check whether there is checkpoint which is not evaluated\n",
    "        cur_epoch_id, cur_ckpt = get_no_evaluated_ckpt(ckpt_dir, ckpt_record_file)\n",
    "        if cur_epoch_id == -1 or int(float(cur_epoch_id)) < args.start_epoch:\n",
    "            wait_second = 30\n",
    "            print('Wait %s second for next check: %s' % (wait_second, ckpt_dir))\n",
    "            time.sleep(wait_second)\n",
    "            continue\n",
    "\n",
    "        # load checkpoint\n",
    "        train_utils.load_checkpoint(model, filename=cur_ckpt)\n",
    "\n",
    "        # start evaluation\n",
    "        cur_result_dir = os.path.join(root_result_dir, 'epoch_%s' % cur_epoch_id, cfg.TEST.SPLIT)\n",
    "        tb_dict = eval_one_epoch(model, test_loader, cur_epoch_id, cur_result_dir, logger)\n",
    "\n",
    "        step = int(float(cur_epoch_id))\n",
    "        if step == float(cur_epoch_id):\n",
    "            for key, val in tb_dict.items():\n",
    "                tb_log.add_scalar(key, val, step)\n",
    "\n",
    "        # record this epoch which has been evaluated\n",
    "        with open(ckpt_record_file, 'a') as f:\n",
    "            print('%s' % cur_epoch_id, file=f)\n",
    "        logger.info('Epoch %s has been evaluated' % cur_epoch_id)\n",
    "\n",
    "\n",
    "def create_dataloader(logger):\n",
    "    mode = 'TEST' if args.test else 'EVAL'\n",
    "    DATA_PATH = os.path.join('..', 'data')\n",
    "\n",
    "    # create dataloader\n",
    "    test_set = KittiRCNNDataset(root_dir=DATA_PATH, npoints=cfg.RPN.NUM_POINTS, split=cfg.TEST.SPLIT, mode=mode,\n",
    "                                random_select=args.random_select,\n",
    "                                rcnn_eval_roi_dir=args.rcnn_eval_roi_dir,\n",
    "                                rcnn_eval_feature_dir=args.rcnn_eval_feature_dir,\n",
    "                                classes=cfg.CLASSES,\n",
    "                                logger=logger)\n",
    "\n",
    "    test_loader = DataLoader(test_set, batch_size=args.batch_size, shuffle=False, pin_memory=True,\n",
    "                             num_workers=args.workers, collate_fn=test_set.collate_batch)\n",
    "\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/congcong/FLAG/basenet/PointRCNN/tools/../lib/config.py:187: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  yaml_cfg = edict(yaml.load(f))\n",
      "2020-10-20 17:56:20,366   INFO  **********************Start logging**********************\n",
      "2020-10-20 17:56:20,367   INFO  cfg_file         cfgs/default.yaml\n",
      "2020-10-20 17:56:20,368   INFO  eval_mode        rcnn\n",
      "2020-10-20 17:56:20,368   INFO  eval_all         False\n",
      "2020-10-20 17:56:20,369   INFO  test             False\n",
      "2020-10-20 17:56:20,369   INFO  ckpt             PointRCNN.pth\n",
      "2020-10-20 17:56:20,370   INFO  rpn_ckpt         None\n",
      "2020-10-20 17:56:20,370   INFO  rcnn_ckpt        None\n",
      "2020-10-20 17:56:20,371   INFO  batch_size       1\n",
      "2020-10-20 17:56:20,371   INFO  workers          4\n",
      "2020-10-20 17:56:20,372   INFO  extra_tag        nuscenes\n",
      "2020-10-20 17:56:20,372   INFO  output_dir       None\n",
      "2020-10-20 17:56:20,373   INFO  ckpt_dir         None\n",
      "2020-10-20 17:56:20,373   INFO  save_result      False\n",
      "2020-10-20 17:56:20,374   INFO  save_rpn_feature False\n",
      "2020-10-20 17:56:20,374   INFO  random_select    True\n",
      "2020-10-20 17:56:20,375   INFO  start_epoch      0\n",
      "2020-10-20 17:56:20,375   INFO  rcnn_eval_roi_dir None\n",
      "2020-10-20 17:56:20,376   INFO  rcnn_eval_feature_dir None\n",
      "2020-10-20 17:56:20,376   INFO  set_cfgs         ['RPN.LOC_XZ_FINE', 'False']\n",
      "2020-10-20 17:56:20,377   INFO  Load testing samples from ../data/nusc_kitti_mini/mini_val\n",
      "2020-10-20 17:56:20,378   INFO  Done: total test samples 10\n",
      "2020-10-20 17:56:23,151   INFO  ==> Loading from checkpoint 'PointRCNN.pth'\n",
      "2020-10-20 17:56:23,206   INFO  ==> Done\n",
      "2020-10-20 17:56:23,208   INFO  ---- EPOCH no_number JOINT EVALUATION ----\n",
      "2020-10-20 17:56:23,209   INFO  ==> Output file: ../output/rcnn/default/eval/epoch_no_number/val/nuscenes\n",
      "eval: 100%|██████████| 10/10 [00:01<00:00,  6.36it/s, mode=EVAL, recall=0/0]\n",
      "2020-10-20 17:56:24,788   INFO  -------------------performance of epoch no_number---------------------\n",
      "2020-10-20 17:56:24,789   INFO  2020-10-20 17:56:24.789710\n",
      "2020-10-20 17:56:24,790   INFO  final average detections: 6.100\n",
      "2020-10-20 17:56:24,791   INFO  final average rpn_iou refined: 0.000\n",
      "2020-10-20 17:56:24,792   INFO  final average cls acc: 0.000\n",
      "2020-10-20 17:56:24,793   INFO  final average cls acc refined: 0.000\n",
      "2020-10-20 17:56:24,794   INFO  total roi bbox recall(thresh=0.100): 0 / 0 = 0.000000\n",
      "2020-10-20 17:56:24,795   INFO  total roi bbox recall(thresh=0.300): 0 / 0 = 0.000000\n",
      "2020-10-20 17:56:24,796   INFO  total roi bbox recall(thresh=0.500): 0 / 0 = 0.000000\n",
      "2020-10-20 17:56:24,797   INFO  total roi bbox recall(thresh=0.700): 0 / 0 = 0.000000\n",
      "2020-10-20 17:56:24,797   INFO  total roi bbox recall(thresh=0.900): 0 / 0 = 0.000000\n",
      "2020-10-20 17:56:24,798   INFO  total bbox recall(thresh=0.100): 0 / 0 = 0.000000\n",
      "2020-10-20 17:56:24,799   INFO  total bbox recall(thresh=0.300): 0 / 0 = 0.000000\n",
      "2020-10-20 17:56:24,799   INFO  total bbox recall(thresh=0.500): 0 / 0 = 0.000000\n",
      "2020-10-20 17:56:24,800   INFO  total bbox recall(thresh=0.700): 0 / 0 = 0.000000\n",
      "2020-10-20 17:56:24,801   INFO  total bbox recall(thresh=0.900): 0 / 0 = 0.000000\n",
      "2020-10-20 17:56:24,801   INFO  Averate Precision:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_file--- ../data/nusc_kitti_mini/mini_val/../ImageSets/val.txt\n",
      "split_file--- /home/congcong/FLAG/basenet/PointRCNN/data/nusc_kitti_mini/ImageSets/val.txt\n",
      "image_idx_list--- ['000000', '000001', '000002', '000003', '000004', '000005', '000006', '000007', '000008', '000009']\n",
      "../data/nusc_kitti_mini/mini_val/label_2 ../output/rcnn/default/eval/epoch_no_number/val/nuscenes/final_result/data /home/congcong/FLAG/basenet/PointRCNN/data/nusc_kitti_mini/ImageSets/val.txt 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/congcong/anaconda2/envs/3d_detection/lib/python3.6/site-packages/numba/core/typed_passes.py:314: NumbaPerformanceWarning: \n",
      "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
      "\n",
      "To find out why, try turning on parallel diagnostics, see https://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help.\n",
      "\n",
      "File \"kitti_object_eval_python/eval.py\", line 120:\n",
      "@numba.jit(nopython=True, parallel=True)\n",
      "def d3_box_overlap_kernel(boxes, qboxes, rinc, criterion=-1):\n",
      "^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "2020-10-20 17:56:29,066   INFO  Car AP@0.70, 0.70, 0.70:\n",
      "bbox AP:14.1414, 10.3636, 10.3636\n",
      "bev  AP:14.1414, 12.2727, 12.2727\n",
      "3d   AP:9.0909, 9.0909, 9.0909\n",
      "aos  AP:11.75, 9.04, 9.04\n",
      "Car AP@0.70, 0.50, 0.50:\n",
      "bbox AP:14.1414, 10.3636, 10.3636\n",
      "bev  AP:32.1096, 28.1688, 28.1688\n",
      "3d   AP:20.8845, 16.1616, 16.1616\n",
      "aos  AP:11.75, 9.04, 9.04\n",
      "\n",
      "2020-10-20 17:56:29,067   INFO  result is saved to: ../output/rcnn/default/eval/epoch_no_number/val/nuscenes\n"
     ]
    }
   ],
   "source": [
    "if args.cfg_file is not None:\n",
    "    cfg_from_file(args.cfg_file)\n",
    "if args.set_cfgs is not None:\n",
    "    cfg_from_list(args.set_cfgs)\n",
    "cfg.TAG = os.path.splitext(os.path.basename(args.cfg_file))[0]\n",
    "\n",
    "if args.eval_mode == 'rpn':\n",
    "    cfg.RPN.ENABLED = True\n",
    "    cfg.RCNN.ENABLED = False\n",
    "    root_result_dir = os.path.join('../', 'output', 'rpn', cfg.TAG)\n",
    "    ckpt_dir = os.path.join('../', 'output', 'rpn', cfg.TAG, 'ckpt')\n",
    "elif args.eval_mode == 'rcnn':\n",
    "    cfg.RCNN.ENABLED = True\n",
    "    cfg.RPN.ENABLED = cfg.RPN.FIXED = True\n",
    "    root_result_dir = os.path.join('../', 'output', 'rcnn', cfg.TAG)\n",
    "    ckpt_dir = os.path.join('../', 'output', 'rcnn', cfg.TAG, 'ckpt')\n",
    "elif args.eval_mode == 'rcnn_offline':\n",
    "    cfg.RCNN.ENABLED = True\n",
    "    cfg.RPN.ENABLED = False\n",
    "    root_result_dir = os.path.join('../', 'output', 'rcnn', cfg.TAG)\n",
    "    ckpt_dir = os.path.join('../', 'output', 'rcnn', cfg.TAG, 'ckpt')\n",
    "    assert args.rcnn_eval_roi_dir is not None and args.rcnn_eval_feature_dir is not None\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "if args.ckpt_dir is not None:\n",
    "    ckpt_dir = args.ckpt_dir\n",
    "\n",
    "if args.output_dir is not None:\n",
    "    root_result_dir = args.output_dir\n",
    "\n",
    "os.makedirs(root_result_dir, exist_ok=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    if args.eval_all:\n",
    "        assert os.path.exists(ckpt_dir), '%s' % ckpt_dir\n",
    "        repeat_eval_ckpt(root_result_dir, ckpt_dir)\n",
    "    else:\n",
    "        eval_single_ckpt(root_result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3d_detection",
   "language": "python",
   "name": "3d_detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
